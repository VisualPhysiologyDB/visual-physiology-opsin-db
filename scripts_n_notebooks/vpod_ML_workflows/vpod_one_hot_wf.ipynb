{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f4de42",
   "metadata": {},
   "source": [
    "# <font color=green>deepBreaks Applications</font>\n",
    "## Modeling the phenotypes and spectral tuning sites of opsin proteins based on amino-acid sequence...  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5b43e3c",
   "metadata": {},
   "source": [
    "# <font color=red>Step 0: mySQL DB Setup -</font> Script 0\n",
    "## *The following script sets up the schema for our vizphiz database.*\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667cc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "#import mysql\n",
    "import mysql.connector\n",
    "#install mysql-connector-python // NOT mysql-connector\n",
    "import re\n",
    "import os\n",
    "import datetime \n",
    "import subprocess\n",
    "import shutil \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d651b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password= \"Geass5566!!\" #change to your password\n",
    "  )\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try:\n",
    "  mycursor.execute(\"\"\"\n",
    "  DROP DATABASE vizphiz_db;\n",
    "  \"\"\")\n",
    "  mydb.commit() \n",
    "except:\n",
    "  \"vizphiz_db does not yet exist!\"\n",
    "  pass\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE DATABASE vizphiz_db;\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "USE vizphiz_db;\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE scp\n",
    "(\n",
    "id int unsigned not null primary key,\n",
    "genus varchar(50),\n",
    "species varchar(50),\n",
    "celltype varchar(50),\n",
    "cellsubtype varchar(50),\n",
    "lamdamax decimal(9,5),\n",
    "error decimal(9,5),\n",
    "chromophore varchar(50),\n",
    "method varchar(50),\n",
    "stage varchar(50),\n",
    "refid int,\n",
    "notes varchar(1000)\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE heterologous\n",
    "(\n",
    "hetid int unsigned not null primary key,\n",
    "genus varchar(50),\n",
    "species varchar(50),\n",
    "accession varchar(500),\n",
    "mutations varchar(500),\n",
    "lamdamax decimal(9,5),\n",
    "error decimal(9,5),\n",
    "cellculture varchar(50),\n",
    "purification varchar(50),\n",
    "spectrum varchar(50),\n",
    "sourcetype varchar(50),\n",
    "refid int,\n",
    "notes varchar(1000)\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE links\n",
    "(\n",
    "linkid int unsigned not null primary key,\n",
    "accession varchar(500),\n",
    "maxid int,\n",
    "refid int,\n",
    "evidence varchar(1000)\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE litsearch\n",
    "(\n",
    "searchid int,\n",
    "researcher varchar(50),\n",
    "month int,\n",
    "year int,\n",
    "engine varchar(500),\n",
    "keywords varchar(500)\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE opsins\n",
    "(\n",
    "opsinid int unsigned not null primary key,\n",
    "genefamily varchar(50),\n",
    "genenames varchar(50),\n",
    "genus varchar(50),\n",
    "phylum varchar(25),\n",
    "class varchar(25),\n",
    "species varchar(50),\n",
    "db varchar(50),\n",
    "accession varchar(500),\n",
    "dna varchar(10000),\n",
    "aa varchar(3333),\n",
    "refid int\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "mydb.commit()\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE refs\n",
    "(\n",
    "refid int,\n",
    "doi varchar(1000),\n",
    "searchid int\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit()\n",
    "\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "import mysql\n",
    "import mysql.connector\n",
    "#install mysql-connector-python // NOT mysql-connector\n",
    "import re\n",
    "import os\n",
    "import datetime \n",
    "import subprocess\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ec206",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 1 - Import Literature-Search data into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1eeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\" #change to your password\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "path = 'c:/Users/safra/Documents/GitHub/visual-physiology-opsin-db/vpod_data/VPOD_1.2/raw_database_files'\n",
    "file1 = open(f'{path}/litsearch.tsv', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    if count == 0:\n",
    "      count+=1\n",
    "    else:\n",
    "      columns = line.split(\"\\t\")\n",
    "\n",
    "      mycursor = mydb.cursor()\n",
    "\n",
    "      sql = \"INSERT INTO vizphiz_db.litsearch (searchid, researcher, month, year, engine, keywords) VALUES (%s, %s, %s,%s, %s, %s)\"\n",
    "      val = (columns[0], columns[1], columns[2], columns[3], columns[4], columns[5])\n",
    "      print(sql)\n",
    "      print(val)\n",
    "\n",
    "      mycursor.execute(sql, val)\n",
    "\n",
    "      mydb.commit()\n",
    "\n",
    "      print(mycursor.rowcount, \"record inserted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f9b2c",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 2 - Import References into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b45842",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\" #change to your password\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "path = 'c:/Users/safra/Documents/GitHub/visual-physiology-opsin-db/vpod_data/VPOD_1.2/raw_database_files'\n",
    "file1 = open(f'{path}/references.tsv', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    if count == 0:\n",
    "      count+=1\n",
    "    else:\n",
    "      columns = line.split(\"\\t\")\n",
    "\n",
    "      mycursor = mydb.cursor()\n",
    "\n",
    "      sql = \"INSERT INTO vizphiz_db.refs (refid, doi, searchid) VALUES (%s, %s, %s)\"\n",
    "      val = (columns[0], columns[1], columns[4])\n",
    "      print(sql)\n",
    "      print(val)\n",
    "\n",
    "      mycursor.execute(sql, val)\n",
    "\n",
    "      mydb.commit()\n",
    "\n",
    "      print(mycursor.rowcount, \"record inserted.\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5778bef",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 3 - Import Heterolgous Data into mySQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\" #change to your password\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "path = 'c:/Users/safra/Documents/GitHub/visual-physiology-opsin-db/vpod_data/VPOD_1.2/raw_database_files'\n",
    "file1 = open(f'{path}/heterologous.tsv', 'r', encoding=\"utf8\")\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    if count == 0:\n",
    "      count+=1\n",
    "    else:\n",
    "      columns = line.split(\"\\t\")\n",
    "      print(columns)\n",
    "      mycursor = mydb.cursor()\n",
    "\n",
    "      sql = \"INSERT INTO vizphiz_db.heterologous (hetid, genus, species, accession, mutations, lamdamax, error, cellculture, purification, spectrum, sourcetype, refid) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "      val = (columns[0], columns[1], columns[2], columns[3], columns[4], columns[5], columns[6], columns[7], columns[8], columns[9], columns[10], columns[11])\n",
    "      print(sql)\n",
    "      print(val)\n",
    "\n",
    "      mycursor.execute(sql, val)\n",
    "\n",
    "      mydb.commit()\n",
    "\n",
    "      print(mycursor.rowcount, \"record inserted.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31e8500e",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 4 - Import Seqience Data into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\"\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "path = 'c:/Users/safra/Documents/GitHub/visual-physiology-opsin-db/vpod_data/VPOD_1.2/raw_database_files'\n",
    "file1 = open(f'{path}/opsins.tsv', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    if count == 0:\n",
    "      count+=1\n",
    "    else:\n",
    "      columns = line.split(\"\\t\")\n",
    "\n",
    "      mycursor = mydb.cursor()\n",
    "\n",
    "      sql = \"INSERT INTO vizphiz_db.opsins (opsinid, genefamily, genenames, phylum, class, genus, species, db, accession, dna, aa, refid) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "      val = (columns[0], columns[1], columns[2], columns[3], columns[5], columns[6], columns[7], columns[8], columns[9], columns[10], columns[11], columns [12])\n",
    "      print(sql)\n",
    "      print(val)\n",
    "\n",
    "      mycursor.execute(sql, val)\n",
    "\n",
    "      mydb.commit()\n",
    "\n",
    "      print(mycursor.rowcount, \"record inserted.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6c27589",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 1: Extract Data Subsets From Vizphiz</font>\n",
    "### Output = 8 Different Data Subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33901d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "import mysql\n",
    "import mysql.connector\n",
    "#install mysql-connector-python // NOT mysql-connector\n",
    "import re\n",
    "import os\n",
    "import datetime \n",
    "import subprocess\n",
    "import shutil \n",
    "import csv\n",
    "import fileinput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14765c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory preperation\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seq_report_dir = str(f'vpod_1.2_data_splits_{dt_label}')\n",
    "os.makedirs(seq_report_dir)\n",
    "\n",
    "#declaring all variables for different sequence data subsets and their metadata\n",
    "wd_output = f'{seq_report_dir}/wds.txt'\n",
    "sws_output = f'{seq_report_dir}/uss.txt'\n",
    "mws_output = f'{seq_report_dir}/mls.txt'\n",
    "rod_output = f'{seq_report_dir}/rod.txt'\n",
    "wd_ni_output = f'{seq_report_dir}/vert.txt'\n",
    "wt_vert_output = f'{seq_report_dir}/wt_vert.txt'\n",
    "inv_output = f'{seq_report_dir}/inv_only.txt'\n",
    "wt_inv_output = f'{seq_report_dir}/wt_inv_only.txt'\n",
    "nmoc_output = f'{seq_report_dir}/wt.txt'\n",
    "mut_output = f'{seq_report_dir}/mut_only.txt'\n",
    "wh_metadata = f'{seq_report_dir}/wds_meta.tsv'\n",
    "sw_metadata = f'{seq_report_dir}/uss_meta.tsv'\n",
    "mw_metadata = f'{seq_report_dir}/mls_meta.tsv'\n",
    "rh_metadata = f'{seq_report_dir}/rod_meta.tsv'\n",
    "wd_ni_metadata = f'{seq_report_dir}/vert_meta.tsv'\n",
    "inv_metadata = f'{seq_report_dir}/inv_meta.tsv'\n",
    "nmoc_metadata = f'{seq_report_dir}/wt_meta.tsv'\n",
    "mut_metadata = f'{seq_report_dir}/mut_meta.tsv'\n",
    "wt_vert_metadata = f'{seq_report_dir}/wt_vert_meta.tsv'\n",
    "redundant_datapoints = f'{seq_report_dir}/redundant_datapoints_log.tsv'\n",
    "\n",
    "\n",
    "#Setting the names for the headers at the top of each metadata file\n",
    "meta_data_list = [wh_metadata,sw_metadata,mw_metadata,rh_metadata,wd_ni_metadata,inv_metadata,nmoc_metadata,wt_vert_metadata,mut_metadata]\n",
    "meta_first_line = \"Seq_Id\\tLambda_Max\\tSpecies\\tOpsin_Family\\tPhylum\\tClass\\tAccession\\tMutations\\tRefId\\nBovine\\t500.0000\\tBos_tarus\\tRh1\\tChordata\\tMammalia\\tNM_001014890\\n\"\n",
    "invert_first_line = \"Seq_Id\\tLambda_Max\\tSpecies\\tOpsin_Family\\tPhylum\\tClass\\tAccession\\tMutations\\tRefId\\nSquid\\t473.0000\\tTodarodes_pacificus\\tRh1\\tMollusca\\tCephalopoda\\tX70498\\n\"\n",
    "bovine_seq = \">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\"\n",
    "\n",
    "#misc int variales for the counting loops\n",
    "m = 0\n",
    "s = 0\n",
    "l = 0\n",
    "r = 0\n",
    "c = 0\n",
    "z = 0\n",
    "q = 0\n",
    "wt_vert = 0\n",
    "mut = 0\n",
    "\n",
    "#regular expressions for filtering different opsin family types \n",
    "rod = re.compile('^Rh$|Rh[0-2]|exoRh')\n",
    "d = re.compile(\"^NM_001014890.2$|^NM_001014890$|^P02699.1$\")\n",
    "sws_reg = re.compile('^SWS')\n",
    "uvs_reg = re.compile('^UVS')\n",
    "mws_reg = re.compile('^MWS')\n",
    "lws_reg = re.compile('^LWS')\n",
    "rh1_reg = re.compile('^Rh$|^Rh[0-1]|exoRh')\n",
    "rh2_reg = re.compile('^Rh2')\n",
    "non_viz = re.compile('^POps|MOps|GoC|PeroOps')\n",
    "\n",
    "#Decide if you want to filter out reduant opsin data (identical sequences)\n",
    "#If 'ignore_filter' set to 'True' then redundant data will be kept\n",
    "ignore_filter = False\n",
    "#If 'only_visual_opsins' set to 'True' then only visual opsins will be kept and non-visual opsins (i.e. Pero-opsins) will be ignored/filtered out\n",
    "only_visual_opsins = True\n",
    "#If 'only_visual_opsins' set to 'True' then only functional opsins will be kept and non-functional opsins (i.e. opsins where lmax=0) will be ignored/filtered out\n",
    "ignore_nfo = True\n",
    "#If 'keep_conflicts' set to 'True' then redudant sequences with conflicting lmax values will be kept\n",
    "keep_conflicts = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database=\"vizphiz\",\n",
    "  password=\"Geass5566!!\"\n",
    ") \n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "#sql = \"select DISTINCT o.genus,o.species,o.genefamily,o.accession,h.lamdamax,o.aa,o.phylum,o.class,h.mutations,o.refid from vizphiz_db.opsins o, vizphiz_db.heterologous h WHERE (o.accession = h.accession AND o.refid = h.refid); \"\n",
    "sql = \"\"\"\n",
    "SELECT DISTINCT \n",
    "    o.genus, o.species, o.genefamily, o.accession, \n",
    "    h.lamdamax, o.aa, o.phylum, o.class, h.mutations, o.refid \n",
    "FROM \n",
    "    vizphiz_db.opsins o\n",
    "JOIN \n",
    "    vizphiz_db.heterologous h \n",
    "ON \n",
    "    o.accession = h.accession AND o.refid = h.refid;\n",
    "\"\"\"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "seq_list = []\n",
    "lmax_list = []\n",
    "species_list = []\n",
    "acc_list = []\n",
    "gene_family_list = []\n",
    "conflicting_lmax = {}\n",
    "\n",
    "for x in myresult:\n",
    "  skip = False\n",
    "  lmax = x[4]  \n",
    "  try:\n",
    "    index = seq_list.index(x[5].strip().replace(' ',''))\n",
    "    lmax_of_index = lmax_list[index]\n",
    "    species_of_index = species_list[index]\n",
    "    acc_of_index = acc_list[index]\n",
    "    gene_family_of_index = gene_family_list[index]\n",
    "  except:\n",
    "    lmax_of_index = None\n",
    "    \n",
    "  species_check = str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')\n",
    "  if (x[5].strip() in seq_list) and (float(x[4]) != float(lmax_of_index)) and (lmax_of_index != None):\n",
    "    # Redundant sequence found\n",
    "    # Handle conflicting lmax values\n",
    "    skip = True\n",
    "    with open(redundant_datapoints, 'a+') as f:\n",
    "      f.write(f'''Accessions {acc_of_index} and {x[3]} encode the same sequence but have conflicting lmax values ({lmax_of_index} and {lmax} respectively).\\n''')\n",
    "      if species_of_index != species_check:\n",
    "        f.write(f'''The two sequences are from different species ({species_of_index} and {species_check}).\\n''')\n",
    "      else:  \n",
    "        f.write(f'''The two sequences are from the same species ({species_of_index}).\\n''')\n",
    "      f.write(f'''We will be taking the average of all conflicting values, and dropping this entry from the final datasplits.\\n''')\n",
    "      f.write(f'''Note - the gene families of the two sequences are {gene_family_of_index} and {x[2]} - if this raises concern, please double check the entries to resolve this issue.\\n\\n''')\n",
    "    \n",
    "    if keep_conflicts == False:\n",
    "      # Store conflicting lmax values to modify original with average of all conflicting values\n",
    "      if acc_of_index not in conflicting_lmax:\n",
    "          conflicting_lmax[acc_of_index] = [float(lmax_of_index), float(x[4])]  # Convert x[4] to float\n",
    "      else:\n",
    "          conflicting_lmax[acc_of_index].append(float(x[4]))\n",
    "    else:\n",
    "      skip = False\n",
    "        \n",
    "  elif (x[5].strip().replace(' ','') in seq_list) and (x[4] == lmax_of_index):\n",
    "    # Redundant sequence found\n",
    "    # Handle identical sequences and lmax values\n",
    "    # Skipping exactly redundant entries \n",
    "    skip = True\n",
    "    with open(redundant_datapoints, 'a+') as f:\n",
    "      f.write(f'''Accessions {acc_of_index} and {x[3]} encode the same sequence and have the same lmax values ({lmax_of_index}).''')\n",
    "      if species_of_index != species_check:\n",
    "        f.write(f'''\\nDespite that the two sequences are from different species ({species_of_index} and {species_check}) we will skip this entry but take the value from the first entry.\\nNote - the gene families of the two sequences are {gene_family_of_index} and {x[2]} -  if this raises concern, please double check the entries to resolve this issue.\\n\\n''')\n",
    "      else:\n",
    "        f.write(f'''Because the two sequences are from the same species ({species_of_index}) we will skip this entry and only keep the value from the first entry.\\n\\n''')\n",
    "  else:\n",
    "    # Store new sequence data\n",
    "    species_list.append(species_check)\n",
    "    gene_family_list.append(x[2])\n",
    "    acc_list.append(x[3])\n",
    "    lmax_list.append(lmax)\n",
    "    seq_list.append(x[5].strip().replace(' ',''))\n",
    "  \n",
    "  if ignore_filter == True:\n",
    "    skip = False\n",
    "    \n",
    "  if only_visual_opsins == True:\n",
    "    if non_viz.match(x[2]):\n",
    "      skip = True\n",
    "      \n",
    "  if (lmax == 0 and ignore_nfo == True) or (skip == True):\n",
    "    pass\n",
    "  else:    \n",
    "  #SEQUENCE-DATA SECTION\n",
    "    #whole-dataset    \n",
    "    with open(wd_output, 'a') as f:\n",
    "      if m == 0:\n",
    "          f.write(bovine_seq)\n",
    "      if (d.match(x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        m += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(m)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    #vertebrate dataset\n",
    "    with open(wd_ni_output, 'a') as f:\n",
    "      if x[6] != \"Chordata\" or d.match(x[3]):\n",
    "        pass\n",
    "      else:\n",
    "        if c == 0:\n",
    "          f.write(bovine_seq)\n",
    "        c += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(c)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    #invertebrate dataset\n",
    "    with open(inv_output, 'a') as f:\n",
    "      if (x[6] != \"Chordata\"):\n",
    "        if q == 0:\n",
    "          f.write(\">Squid\\nMGRDLRDNETWWYNPSIVVHPHWREFDQVPDAVYYSLGIFIGICGIIGCGGNGIVIYLFTKTKSLQTPANMFIINLAFSDFTFSLVNGFPLMTISCFLKKWIFGFAACKVYGFIGGIFGFMSIMTMAMISIDRYNVIGRPMAASKKMSHRRAFIMIIFVWLWSVLWAIGPIFGWGAYTLEGVLCNCSFDYISRDSTTRSNILCMFILGFFGPILIIFFCYFNIVMSVSNHEKEMAAMAKRLNAKELRKAQAGANAEMRLAKISIVIVSQFLLSWSPYAVVALLAQFGPLEWVTPYAAQLPVMFAKASAIHNPMIYSVSHPKFREAISQTFPWVLTCCQFDDKETEDDKDAETEIPAGESSDAAPSADAAQMKEMMAMMQKMQQQQAAYPPQGYAPPPQGYPPQGYPPQGYPPQGYPPQGYPPPPQGAPPQGAPPAAPPQGVDNQAYQA\\n\")\n",
    "        q += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(q)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "      else:\n",
    "        pass\n",
    "    \n",
    "    #wild-type dataset\n",
    "    with open(nmoc_output, 'a') as f:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        if z == 0:\n",
    "          f.write(bovine_seq)\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:\n",
    "          z += 1 \n",
    "          #This makes the fasta format file\n",
    "          seq = \">S\" + str(z)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "\n",
    "    #wild-type vertebrates dataset\n",
    "    with open(wt_vert_output, 'a') as f:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if (x[6] != \"Chordata\") or d.match(x[3]) or ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        if wt_vert == 0:\n",
    "          f.write(bovine_seq)\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:\n",
    "          wt_vert += 1 \n",
    "          #This makes the fasta format file\n",
    "          seq = \">S\" + str(wt_vert)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "\n",
    "    #just mutants dataset\n",
    "    with open(mut_output, 'a') as f:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        if mut == 0:\n",
    "          f.write(bovine_seq)\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:\n",
    "          mut += 1 \n",
    "          #This makes the fasta format file\n",
    "          seq = \">M\" + str(mut)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "      else:\n",
    "        pass\n",
    "    \n",
    "    #UVS and SWS dataset\n",
    "    with open(sws_output, 'a') as f:\n",
    "      p = re.compile('^SWS|^UVS')\n",
    "      if p.match(x[2]) and x[6] == \"Chordata\":\n",
    "        s+=1\n",
    "        if s == 1:\n",
    "          f.write(bovine_seq)\n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(s)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    #MWS and LWS dataset\n",
    "    with open(mws_output, 'a') as f:\n",
    "      p = re.compile('^MWS|^LWS')\n",
    "      if p.match(x[2]) and x[6] == \"Chordata\":\n",
    "        l+=1\n",
    "        if l == 1:\n",
    "          f.write(bovine_seq)\n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(l)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    #rods dataset\n",
    "    with open(rod_output, 'a') as f:\n",
    "      p = re.compile('Rh[0-2]|exoRh')\n",
    "      if p.match(x[2]):\n",
    "        if r == 0:\n",
    "          f.write(bovine_seq)\n",
    "        if (x[6] != \"Chordata\") or d.match(x[3]):\n",
    "          pass\n",
    "        else:\n",
    "          r+=1\n",
    "          #This makes the fasta format file\n",
    "          seq = \">S\" + str(r)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "\n",
    "  #METADATA SECTION - same idea and naming convention for the files as above. \n",
    "    with open(wh_metadata, 'a') as g:\n",
    "      if m == 1:\n",
    "          g.write(meta_first_line)      \n",
    "      if (d.match(x[3])):\n",
    "        pass\n",
    "      else:        \n",
    "        md =  str(\"S\" + str(m) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" +str(x[9]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(wd_ni_metadata, 'a') as g:\n",
    "      if x[6] != \"Chordata\" or d.match(x[3]):\n",
    "        pass\n",
    "      else:\n",
    "        if c == 1:\n",
    "          g.write(meta_first_line)      \n",
    "\n",
    "        md =  str(\"S\" + str(c) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" + str(x[9]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(inv_metadata, 'a') as g:\n",
    "      if (x[6] != \"Chordata\"):\n",
    "        if q == 1:\n",
    "          g.write(invert_first_line)\n",
    "        md =  str(\"S\" + str(q) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" + str(x[9]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "      else:\n",
    "        pass\n",
    "          \n",
    "    with open(sw_metadata, 'a') as g:\n",
    "      p = re.compile('^SWS|^UVS')\n",
    "      if p.match(x[2]) and x[6] == \"Chordata\":\n",
    "        if s == 1:\n",
    "          g.write(meta_first_line)\n",
    "        md =  str(\"S\" + str(s) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" + str(x[9]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(mw_metadata, 'a') as g:\n",
    "      p = re.compile('^MWS|^LWS')\n",
    "      if p.match(x[2]) and x[6] == \"Chordata\":\n",
    "        if l == 1:\n",
    "          g.write(meta_first_line)        \n",
    "        md =  str(\"S\" + str(l) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" + str(x[9]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(rh_metadata, 'a') as g:\n",
    "      p = re.compile('Rh[0-3]|exoRh')\n",
    "\n",
    "      if p.match(x[2]):\n",
    "        if r == 1:\n",
    "          g.write(meta_first_line)      \n",
    "        if (x[6] != \"Chordata\") or d.match(x[3]):\n",
    "          pass\n",
    "        else:  \n",
    "          md =  str(\"S\" + str(r) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" + str(x[9]).strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "\n",
    "    with open(nmoc_metadata, 'a') as g:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        if z == 1:\n",
    "          g.write(meta_first_line)      \n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:        \n",
    "          md =  str(\"S\" + str(z) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" + str(x[9]).strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "          \n",
    "    with open(wt_vert_metadata, 'a') as g:\n",
    "      if (x[6] != \"Chordata\") or d.match(x[3]) or ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        if wt_vert == 1:\n",
    "          g.write(meta_first_line)      \n",
    "\n",
    "        md =  str(\"S\" + str(wt_vert) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" + str(x[9]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(mut_metadata, 'a') as g:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        if mut == 1:\n",
    "          g.write(meta_first_line)      \n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:        \n",
    "          md =  str(\"M\" + str(mut) + \"\\t\" + str(lmax).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\t\" + str(x[9]).strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "      else:\n",
    "        pass\n",
    "      \n",
    "mydb.close()\n",
    "\n",
    "# Calculate average lmax and update for sequences flagged as haivng redundant entries with conflicting lmax values in the database\n",
    "for dsplit in meta_data_list:\n",
    "    file = fileinput.input(dsplit, inplace=True)\n",
    "    for line in file:\n",
    "        modify = False\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        lmax = fields[1] \n",
    "        accession = fields[6] \n",
    "        for key in conflicting_lmax.keys():\n",
    "            if accession == key:\n",
    "                modify = True\n",
    "        if modify == True:\n",
    "            conflicting_lmax[accession]\n",
    "            avg_lmax = float(sum(conflicting_lmax[accession])) / float(len(conflicting_lmax[accession]))\n",
    "            fields[1] = str(avg_lmax)\n",
    "        print(\"\\t\".join(fields))  # Print the modified line, which overwrites the original line in the file\n",
    "    file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an additional sequence file where all the mutants are \n",
    "#added to the bottom of the wild-type sequences so they can be aligned for WT model test.\n",
    "mut_only = open(mut_output).readlines()\n",
    "mut_nmoc = f'{seq_report_dir}/wt_mut_added.txt'\n",
    "shutil.copy(nmoc_output , mut_nmoc)\n",
    "x = 0\n",
    "for lines in mut_only:\n",
    "  if x <= 1:\n",
    "    if x == 0:\n",
    "      with open(mut_nmoc, 'a') as m:\n",
    "        m.write('\\n')\n",
    "    else:\n",
    "      pass\n",
    "    x+=1\n",
    "  else:\n",
    "    with open(mut_nmoc, 'a') as m:\n",
    "      m.write(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "261d0aca",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 2: Align Raw Data w/MAFFT and Format for 'deepBreaks'</font>\n",
    "## REMINDER - You will need to change the directory for the 'mafft_exe' variable to the one of your own operating system!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import MafftCommandline\n",
    "from Bio import AlignIO\n",
    "\n",
    "data_split_list = [wd_output,sws_output,mws_output,rod_output,wd_ni_output,inv_output,nmoc_output,wt_vert_output,mut_nmoc,mut_output]\n",
    "output_list = []\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat' \n",
    "\n",
    "for data in data_split_list:\n",
    "    output = f'{data.split(\".\")[0]}.{data.split(\".\")[1]}_aligned.txt'\n",
    "    mafft_cline = MafftCommandline(mafft_exe, input=f'./{data}')\n",
    "    #print(mafft_cline)\n",
    "    stdout, stderr = mafft_cline()\n",
    "\n",
    "    with open(output, \"w\") as handle:\n",
    "        handle.write(stdout)\n",
    "        #print(handle)\n",
    "    align = AlignIO.read(output, \"fasta\")\n",
    "    output_list.append(f'{output}')\n",
    "\n",
    "print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e914c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enters list of aligned text files here.\n",
    "inputs = output_list\n",
    "deep_breaks_input_data = []\n",
    "\n",
    "i=0\n",
    "k = 0\n",
    "for item in inputs:\n",
    "    print(item)\n",
    "    lines = open(inputs[i]).readlines()\n",
    "    output = f'./{inputs[i].split(\".\")[0]}.{inputs[i].split(\".\")[1]}_VPOD_1.2_het.fasta'\n",
    "    deep_breaks_input_data.append(output)\n",
    "    print(output)\n",
    "    file = open(output, 'w')\n",
    "    m=0\n",
    "    for line in lines:\n",
    "        snip = str(lines[k])\n",
    "        if '>' in snip:\n",
    "            if m == 0:\n",
    "                m+=1\n",
    "            else:\n",
    "                file.write(\"\\n\")\n",
    "            file.write(snip)\n",
    "        else:\n",
    "            entry = \"\"\n",
    "            entry = str(snip.replace(\"\\n\",\"\"))\n",
    "            file.write(entry)\n",
    "        k+=1\n",
    "    k = 0\n",
    "    i+=1\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deep_breaks_input_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2969791",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 3: deepBreaks</font>\n",
    "## THIS IS A LONG SECTION! \n",
    "### **Output** = folder containing all results from model training, including comparison of model performances, an amino-acid site importance report + figures, and the top 5 trained models in a .pkl file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eed2c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# importing deepBreaks libraries \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepBreaks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_models, get_scores, get_params, get_simp_params, make_pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepBreaks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepBreaks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureSelection, CollinearCare\n",
      "File \u001b[1;32mc:\\Users\\safra\\anaconda3\\envs\\deepBreaks\\lib\\site-packages\\deepBreaks\\utils.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "File \u001b[1;32mc:\\Users\\safra\\anaconda3\\envs\\deepBreaks\\lib\\site-packages\\pandas\\__init__.py:77\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     ArrowDtype,\n\u001b[0;32m     80\u001b[0m     Int8Dtype,\n\u001b[0;32m     81\u001b[0m     Int16Dtype,\n\u001b[0;32m     82\u001b[0m     Int32Dtype,\n\u001b[0;32m     83\u001b[0m     Int64Dtype,\n\u001b[0;32m     84\u001b[0m     UInt8Dtype,\n\u001b[0;32m     85\u001b[0m     UInt16Dtype,\n\u001b[0;32m     86\u001b[0m     UInt32Dtype,\n\u001b[0;32m     87\u001b[0m     UInt64Dtype,\n\u001b[0;32m     88\u001b[0m     Float32Dtype,\n\u001b[0;32m     89\u001b[0m     Float64Dtype,\n\u001b[0;32m     90\u001b[0m     CategoricalDtype,\n\u001b[0;32m     91\u001b[0m     PeriodDtype,\n\u001b[0;32m     92\u001b[0m     IntervalDtype,\n\u001b[0;32m     93\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     94\u001b[0m     StringDtype,\n\u001b[0;32m     95\u001b[0m     BooleanDtype,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     NA,\n\u001b[0;32m     98\u001b[0m     isna,\n\u001b[0;32m     99\u001b[0m     isnull,\n\u001b[0;32m    100\u001b[0m     notna,\n\u001b[0;32m    101\u001b[0m     notnull,\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     Index,\n\u001b[0;32m    104\u001b[0m     CategoricalIndex,\n\u001b[0;32m    105\u001b[0m     RangeIndex,\n\u001b[0;32m    106\u001b[0m     MultiIndex,\n\u001b[0;32m    107\u001b[0m     IntervalIndex,\n\u001b[0;32m    108\u001b[0m     TimedeltaIndex,\n\u001b[0;32m    109\u001b[0m     DatetimeIndex,\n\u001b[0;32m    110\u001b[0m     PeriodIndex,\n\u001b[0;32m    111\u001b[0m     IndexSlice,\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     NaT,\n\u001b[0;32m    114\u001b[0m     Period,\n\u001b[0;32m    115\u001b[0m     period_range,\n\u001b[0;32m    116\u001b[0m     Timedelta,\n\u001b[0;32m    117\u001b[0m     timedelta_range,\n\u001b[0;32m    118\u001b[0m     Timestamp,\n\u001b[0;32m    119\u001b[0m     date_range,\n\u001b[0;32m    120\u001b[0m     bdate_range,\n\u001b[0;32m    121\u001b[0m     Interval,\n\u001b[0;32m    122\u001b[0m     interval_range,\n\u001b[0;32m    123\u001b[0m     DateOffset,\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     to_numeric,\n\u001b[0;32m    126\u001b[0m     to_datetime,\n\u001b[0;32m    127\u001b[0m     to_timedelta,\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     Flags,\n\u001b[0;32m    130\u001b[0m     Grouper,\n\u001b[0;32m    131\u001b[0m     factorize,\n\u001b[0;32m    132\u001b[0m     unique,\n\u001b[0;32m    133\u001b[0m     value_counts,\n\u001b[0;32m    134\u001b[0m     NamedAgg,\n\u001b[0;32m    135\u001b[0m     array,\n\u001b[0;32m    136\u001b[0m     Categorical,\n\u001b[0;32m    137\u001b[0m     set_eng_float_format,\n\u001b[0;32m    138\u001b[0m     Series,\n\u001b[0;32m    139\u001b[0m     DataFrame,\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\safra\\anaconda3\\envs\\deepBreaks\\lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\safra\\anaconda3\\envs\\deepBreaks\\lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmissing.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\safra\\anaconda3\\envs\\deepBreaks\\lib\\site-packages\\pandas\\_libs\\tslibs\\__init__.py:40\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalize_pydatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_supported_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m ]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes  \u001b[38;5;66;03m# pylint: disable=import-self\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m localize_pydatetime\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     42\u001b[0m     Resolution,\n\u001b[0;32m     43\u001b[0m     periods_per_day,\n\u001b[0;32m     44\u001b[0m     periods_per_second,\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnattype\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     NaT,\n\u001b[0;32m     48\u001b[0m     NaTType,\n\u001b[0;32m     49\u001b[0m     iNaT,\n\u001b[0;32m     50\u001b[0m     nat_strings,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32mconversion.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32moffsets.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.offsets\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtimestamps.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.timestamps\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtimedeltas.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.timedeltas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtimezones.pyx:10\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.timezones\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\safra\\anaconda3\\envs\\deepBreaks\\lib\\zoneinfo\\__init__.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZoneInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset_tzpath\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalidTZPathWarning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m ]\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _tzpath\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZoneInfoNotFoundError\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1039\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils import get_models, get_scores, get_params, get_simp_params, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from deepBreaks.models import model_compare_cv, finalize_top, importance_from_pipe, mean_importance, summarize_results\n",
    "from deepBreaks.visualization import plot_scatter, dp_plot, plot_imp_model, plot_imp_all\n",
    "from deepBreaks.preprocessing import write_fasta\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "#assign your path to folder containing all the datasplits\n",
    "path = './vpod_1.2_data_splits_2024-10-19_10-30-09'\n",
    "# path to sequences of interest\n",
    "seqFileName = f'{path}/Karyasuyama_T1_ops.fasta' \n",
    "# path to corresponding metadata of interest\n",
    "metaDataFileName = f'{path}/Karyasuyama_T1_ops_meta.tsv' \n",
    "# name of the phenotype\n",
    "mt = 'Lambda_Max'\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'reg' \n",
    "\n",
    "gap_threshold = 0.5\n",
    "\n",
    "#Whether or not you want to drop the reference sequence from the training data- Usually 'Bovine' or 'Squid'\n",
    "drop_ref = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592e45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direcory preparation\n"
     ]
    }
   ],
   "source": [
    "# making a unique directory for saving the reports of the analysis\n",
    "print('direcory preparation')\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seqFile = seqFileName.split('/')[2]\n",
    "#print(seqFile)\n",
    "seqFile = seqFile.split('.')[0]+'.'+seqFile.split('.')[1]\n",
    "#print(seqFile)\n",
    "report_dir = str(seqFile +'_' + mt + '_' + dt_label)\n",
    "os.makedirs(report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0ba03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading meta-data\n",
      "reading fasta file\n",
      "wt_aligned_VPOD_1.2_het_gap_dropped.fasta was saved successfully\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 240 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('reading meta-data')\n",
    "# importing metadata\n",
    "meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "# importing sequences data\n",
    "print('reading fasta file')\n",
    "\n",
    "tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=gap_threshold)\n",
    "\n",
    "shutil.copy2(f'{seqFileName}',report_dir)\n",
    "write_fasta(dat = tr, fasta_file = f'{seqFile}_gap_dropped.fasta' , report_dir = report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reference_seq = tr.loc['Bovine'].copy()\n",
    "    ref_seq_name = 'bovine'\n",
    "    if drop_ref == True:\n",
    "        meta_data = meta_data.drop('Bovine')\n",
    "    #print(bovine)\n",
    "except:\n",
    "    reference_seq = tr.loc['Squid'].copy()\n",
    "    ref_seq_name = 'squid'\n",
    "    #print(squid)\n",
    "reference_seq.to_csv(path_or_buf= f'{report_dir}/ref_sequence.csv',index = True,mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddafbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_data_filtered = meta_data[meta_data['Mutations'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 354)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ce749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>...</th>\n",
       "      <th>p345</th>\n",
       "      <th>p346</th>\n",
       "      <th>p347</th>\n",
       "      <th>p348</th>\n",
       "      <th>p349</th>\n",
       "      <th>p350</th>\n",
       "      <th>p351</th>\n",
       "      <th>p352</th>\n",
       "      <th>p353</th>\n",
       "      <th>Lambda_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bovine</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "      <td>Q</td>\n",
       "      <td>V</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>494.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p1   p2   p3 p4 p5 p6 p7 p8 p9 p10  ... p345 p346 p347 p348 p349  \\\n",
       "Bovine    M    N    G  T  E  G  P  N  F   Y  ...  NaN  NaN    T    S    Q   \n",
       "S1        M    N    G  T  E  G  P  Y  F   Y  ...    A  NaN  NaN    S    S   \n",
       "S2      NaN  NaN  NaN  T  E  G  P  Y  F   Y  ...    A  NaN  NaN    S    S   \n",
       "S3      NaN  NaN  NaN  T  E  G  P  D  F   Y  ...    A  NaN  NaN    S    S   \n",
       "S4      NaN  NaN  NaN  T  E  G  P  F  F   Y  ...    A  NaN  NaN    S    S   \n",
       "\n",
       "       p350 p351 p352 p353 Lambda_Max  \n",
       "Bovine    V    A    P    A      500.0  \n",
       "S1        V    S    P    A      502.0  \n",
       "S2        V    S    P    A      502.0  \n",
       "S3        V    S    P    A      481.0  \n",
       "S4        V    S    P    A      494.0  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7b45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data is:  (364, 353)\n"
     ]
    }
   ],
   "source": [
    "y = tr.loc[:, mt].values\n",
    "tr.drop(mt, axis=1, inplace=True)\n",
    "print('Shape of data is: ', tr.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69979653",
   "metadata": {},
   "source": [
    "**Attention**: metadata and sequences data should have the names as their row names and for each sequence their must be a value in the meta data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata looks like this:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lambda_Max</th>\n",
       "      <th>Species</th>\n",
       "      <th>Opsin_Family</th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Class</th>\n",
       "      <th>Accession</th>\n",
       "      <th>Mutations</th>\n",
       "      <th>RefId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seq_Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bovine</th>\n",
       "      <td>500.0</td>\n",
       "      <td>Bos_tarus</td>\n",
       "      <td>Rh1</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>NM_001014890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>502.0</td>\n",
       "      <td>Neoniphon_sammara</td>\n",
       "      <td>Rh1</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>U57536.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>502.0</td>\n",
       "      <td>Neoniphon_argenteus</td>\n",
       "      <td>Rh1</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>U57540.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>481.0</td>\n",
       "      <td>Neoniphon_aurolineatus</td>\n",
       "      <td>Rh1</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>U57541.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>494.0</td>\n",
       "      <td>Sargocentron_punctatissimum</td>\n",
       "      <td>Rh1</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>U57543.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Lambda_Max                      Species Opsin_Family    Phylum  \\\n",
       "Seq_Id                                                                   \n",
       "Bovine       500.0                    Bos_tarus          Rh1  Chordata   \n",
       "S1           502.0            Neoniphon_sammara          Rh1  Chordata   \n",
       "S2           502.0          Neoniphon_argenteus          Rh1  Chordata   \n",
       "S3           481.0       Neoniphon_aurolineatus          Rh1  Chordata   \n",
       "S4           494.0  Sargocentron_punctatissimum          Rh1  Chordata   \n",
       "\n",
       "              Class     Accession  Mutations  RefId  \n",
       "Seq_Id                                               \n",
       "Bovine     Mammalia  NM_001014890        NaN    NaN  \n",
       "S1      Actinopteri      U57536.1        NaN  160.0  \n",
       "S2      Actinopteri      U57540.1        NaN  160.0  \n",
       "S3      Actinopteri      U57541.1        NaN  160.0  \n",
       "S4      Actinopteri      U57543.1        NaN  160.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('metadata looks like this:')\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fb6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence data looks like this:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>...</th>\n",
       "      <th>p344</th>\n",
       "      <th>p345</th>\n",
       "      <th>p346</th>\n",
       "      <th>p347</th>\n",
       "      <th>p348</th>\n",
       "      <th>p349</th>\n",
       "      <th>p350</th>\n",
       "      <th>p351</th>\n",
       "      <th>p352</th>\n",
       "      <th>p353</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bovine</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "      <td>Q</td>\n",
       "      <td>V</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p1   p2   p3 p4 p5 p6 p7 p8 p9 p10  ... p344 p345 p346 p347 p348  \\\n",
       "Bovine    M    N    G  T  E  G  P  N  F   Y  ...  NaN  NaN  NaN    T    S   \n",
       "S1        M    N    G  T  E  G  P  Y  F   Y  ...    S    A  NaN  NaN    S   \n",
       "S2      NaN  NaN  NaN  T  E  G  P  Y  F   Y  ...    S    A  NaN  NaN    S   \n",
       "S3      NaN  NaN  NaN  T  E  G  P  D  F   Y  ...    S    A  NaN  NaN    S   \n",
       "S4      NaN  NaN  NaN  T  E  G  P  F  F   Y  ...    S    A  NaN  NaN    S   \n",
       "\n",
       "       p349 p350 p351 p352 p353  \n",
       "Bovine    Q    V    A    P    A  \n",
       "S1        S    V    S    P    A  \n",
       "S2        S    V    S    P    A  \n",
       "S3        S    V    S    P    A  \n",
       "S4        S    V    S    P    A  \n",
       "\n",
       "[5 rows x 353 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sequence data looks like this:')\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ev = 1239.8 / np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "140f567b",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "In this step, we do all these steps:\n",
    "1. dropping columns with a number of missing values above a certain threshold  \n",
    "2. dropping zero entropy columns  \n",
    "3. imputing missing values with the mode of that column  \n",
    "4. replacing cases with a frequency below a threshold (default 1.5%) with the mode of that column\n",
    "5. dropping zero entropy columns\n",
    "6. use statistical tests (each position against the phenotype) and drop columns with p-values below a threshold (default 0.25)\n",
    "7. one-hot encode the remaining columns\n",
    "8. calculate the pair-wise distance matrix for all of the columns\n",
    "9. use the distance matrix for DBSCAN and cluster the correlated positions together\n",
    "10. keep only one column (closes to center of each cluster) for each group and drop the rest from the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.025)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=False)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=False))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e97be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting rf...\n",
      "Fitting Adaboost...\n",
      "Fitting et...\n",
      "Fitting gbr...\n",
      "Fitting dt...\n",
      "Fitting lr...\n",
      "Fitting Lasso...\n",
      "Fitting LassoLars...\n",
      "Fitting BayesianRidge...\n",
      "Fitting HubR...\n",
      "Fitting lgbm...\n",
      "Fitting xgb...\n",
      "CPU times: total: 6.41 s\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "report, top = model_compare_cv(X=tr, y=y, preprocess_pipe=prep_pipeline,\n",
    "                               models_dict=get_models(ana_type=ana_type),\n",
    "                               scoring=get_scores(ana_type=ana_type),\n",
    "                               report_dir=report_dir,\n",
    "                               cv=10, ana_type=ana_type, cache_dir=report_dir, random_state=899)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af902297",
   "metadata": {},
   "source": [
    "MAE = Mean Absolute Error\n",
    "\n",
    "MSE = Mean Squared Error\n",
    "\n",
    "RMSE = Rooted Mean Square Error\n",
    "\n",
    "MAPE = Mean Absolute % Error - the average magnitude of error produced by a model, or how far off predictions are on average. A MAPE value of 20% means that the average absolute percentage difference between the predictions and the actuals is 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f4a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gbr</th>\n",
       "      <td>9.134537e-01</td>\n",
       "      <td>9.468375e+00</td>\n",
       "      <td>2.311198e+02</td>\n",
       "      <td>1.501976e+01</td>\n",
       "      <td>2.045131e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>9.095452e-01</td>\n",
       "      <td>1.000385e+01</td>\n",
       "      <td>2.615940e+02</td>\n",
       "      <td>1.579550e+01</td>\n",
       "      <td>2.169751e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>9.015403e-01</td>\n",
       "      <td>9.574426e+00</td>\n",
       "      <td>2.750536e+02</td>\n",
       "      <td>1.621832e+01</td>\n",
       "      <td>2.065449e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>8.971492e-01</td>\n",
       "      <td>9.676384e+00</td>\n",
       "      <td>2.833890e+02</td>\n",
       "      <td>1.665826e+01</td>\n",
       "      <td>2.123647e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>8.920063e-01</td>\n",
       "      <td>1.006437e+01</td>\n",
       "      <td>2.956137e+02</td>\n",
       "      <td>1.690104e+01</td>\n",
       "      <td>2.175188e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>8.780826e-01</td>\n",
       "      <td>1.347273e+01</td>\n",
       "      <td>3.540620e+02</td>\n",
       "      <td>1.819032e+01</td>\n",
       "      <td>2.896764e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>8.670670e-01</td>\n",
       "      <td>1.049149e+01</td>\n",
       "      <td>3.806035e+02</td>\n",
       "      <td>1.880821e+01</td>\n",
       "      <td>2.246077e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>8.467711e-01</td>\n",
       "      <td>1.359799e+01</td>\n",
       "      <td>4.331821e+02</td>\n",
       "      <td>2.023208e+01</td>\n",
       "      <td>2.960081e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>8.467695e-01</td>\n",
       "      <td>1.359790e+01</td>\n",
       "      <td>4.331796e+02</td>\n",
       "      <td>2.023215e+01</td>\n",
       "      <td>2.960088e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HubR</th>\n",
       "      <td>8.167737e-01</td>\n",
       "      <td>1.313968e+01</td>\n",
       "      <td>5.171524e+02</td>\n",
       "      <td>2.166684e+01</td>\n",
       "      <td>2.804736e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>8.152902e-01</td>\n",
       "      <td>1.202465e+01</td>\n",
       "      <td>5.329559e+02</td>\n",
       "      <td>2.238235e+01</td>\n",
       "      <td>2.574769e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>-7.006659e+17</td>\n",
       "      <td>1.805927e+10</td>\n",
       "      <td>2.481580e+21</td>\n",
       "      <td>3.213673e+10</td>\n",
       "      <td>3.886256e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         R2           MAE           MSE          RMSE  \\\n",
       "gbr            9.134537e-01  9.468375e+00  2.311198e+02  1.501976e+01   \n",
       "BayesianRidge  9.095452e-01  1.000385e+01  2.615940e+02  1.579550e+01   \n",
       "xgb            9.015403e-01  9.574426e+00  2.750536e+02  1.621832e+01   \n",
       "rf             8.971492e-01  9.676384e+00  2.833890e+02  1.665826e+01   \n",
       "lgbm           8.920063e-01  1.006437e+01  2.956137e+02  1.690104e+01   \n",
       "Adaboost       8.780826e-01  1.347273e+01  3.540620e+02  1.819032e+01   \n",
       "et             8.670670e-01  1.049149e+01  3.806035e+02  1.880821e+01   \n",
       "LassoLars      8.467711e-01  1.359799e+01  4.331821e+02  2.023208e+01   \n",
       "Lasso          8.467695e-01  1.359790e+01  4.331796e+02  2.023215e+01   \n",
       "HubR           8.167737e-01  1.313968e+01  5.171524e+02  2.166684e+01   \n",
       "dt             8.152902e-01  1.202465e+01  5.329559e+02  2.238235e+01   \n",
       "lr            -7.006659e+17  1.805927e+10  2.481580e+21  3.213673e+10   \n",
       "\n",
       "                       MAPE  \n",
       "gbr            2.045131e-02  \n",
       "BayesianRidge  2.169751e-02  \n",
       "xgb            2.065449e-02  \n",
       "rf             2.123647e-02  \n",
       "lgbm           2.175188e-02  \n",
       "Adaboost       2.896764e-02  \n",
       "et             2.246077e-02  \n",
       "LassoLars      2.960081e-02  \n",
       "Lasso          2.960088e-02  \n",
       "HubR           2.804736e-02  \n",
       "dt             2.574769e-02  \n",
       "lr             3.886256e+07  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.025)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=True)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=True))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df108475",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top = []\n",
    "mtml = []\n",
    "for model in top:\n",
    "    modified_top.append(make_pipeline(steps=[('prep', prep_pipeline), model.steps[-1]]))\n",
    "    my_top_models = str(model[1:])\n",
    "    #print(my_top_models)\n",
    "    my_top_models = my_top_models.split(\"'\")[3]\n",
    "    mtml.append(my_top_models)\n",
    "    #print(my_top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7005603",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top = finalize_top(X=tr, y=y, top_models=modified_top, grid_param=get_simp_params(),report_dir=report_dir, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sr = summarize_results(top_models=top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bce71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot = plot_scatter(summary_result=sr, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_imp = mean_importance(top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e644ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_plot(importance=mean_imp,imp_col='mean', model_name='mean', report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = tr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ed0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = prep_pipeline[:4].fit_transform(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in top:\n",
    "    model_name = model.steps[-1][0]\n",
    "    dp_plot(importance=importance_from_pipe(model),\n",
    "            imp_col='standard_value',\n",
    "            model_name = model_name, report_dir=report_dir)\n",
    "    \n",
    "    plot_imp_model(importance=importance_from_pipe(model), \n",
    "               X_train=test_copy, y_train=y, model_name=model_name,\n",
    "                   meta_var='lmax', model_type=ana_type, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = plot_imp_all(final_models=top,\n",
    "                  X_train=tr, y_train=y,\n",
    "                  model_type = ana_type,\n",
    "                  report_dir=report_dir, max_plots=10,\n",
    "                  figsize=(2.5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepBreaks.utils import load_obj\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ae400",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_per_mod = report_dir + '/' + mtml[2] + '.pkl'\n",
    "load_top_mod = load_obj(top_per_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c553a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Here is a list of your top performing models to test...\\n{mtml}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08805113",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 4: Translate Candidate STSs</font> \n",
    "## This section is used to translate candidate STSs to the bovine or squid equivalent.\n",
    "### The bovine and squid sequence dataframes that were saved earlier and are called again here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: Translate Candidate STSs \n",
    "#translate candidate STSs to the bovine or squid equivalent \n",
    "#bovine and squid sequence dataframes were saved earlier and are called again here\n",
    "m = 0\n",
    "tm = ''\n",
    "k=0\n",
    "gaps=0\n",
    "#import importance_report.csv from report_dir\n",
    "true_pos = []\n",
    "aa = []\n",
    "tmd = []\n",
    "df = pd.read_csv(f'{report_dir}\\importance_report.csv')\n",
    "#take the list of important sites and translate them to the bovine standard equivalent, \n",
    "#we do this by taking the site number and subtracting the number of '-' between the start of the sequence and the desired site. \n",
    "for rows in reference_seq.values:  \n",
    "    rows = str(rows)\n",
    "    #print(rows)\n",
    "    if rows == 'nan':\n",
    "    #We want to write the 'true_pos', 'aa', and 'TMD' to the 'importance_report' csv file\n",
    "        gaps += 1\n",
    "        k += 1\n",
    "        true_pos.append('NA')\n",
    "        aa.append('-')\n",
    "        tmd.append('NA')\n",
    "    else:\n",
    "        #print(\"The number of gaps is \" + str(gaps))\n",
    "        k+=1\n",
    "        trans_site = k - gaps\n",
    "        if ref_seq_name == 'bovine':\n",
    "            if trans_site in range(3,37):\n",
    "                tm = 'N-Termina'\n",
    "            elif trans_site in range(37,62):\n",
    "                tm = '1'\n",
    "            elif trans_site in range(74,96):\n",
    "                tm = '2'\n",
    "            elif trans_site in range(111,133):\n",
    "                tm = '3'\n",
    "            elif trans_site in range(153,174):\n",
    "                tm = '4'\n",
    "            elif trans_site in range(203,225):\n",
    "                tm = '5'\n",
    "            elif trans_site in range(253,275):\n",
    "                tm = '6'\n",
    "            elif trans_site in range(287,309):\n",
    "                tm = '7'\n",
    "            else:\n",
    "                tm = 'CT/EC'\n",
    "        else:\n",
    "            if trans_site in range(3,34):\n",
    "                tm = 'N-Termina'\n",
    "            elif trans_site in range(34,59):\n",
    "                tm = '1'\n",
    "            elif trans_site in range(71,97):\n",
    "                tm = '2'\n",
    "            elif trans_site in range(110,132):\n",
    "                tm = '3'\n",
    "            elif trans_site in range(152,173):\n",
    "                tm = '4'\n",
    "            elif trans_site in range(200,225):\n",
    "                tm = '5'\n",
    "            elif trans_site in range(262,284):\n",
    "                tm = '6'\n",
    "            elif trans_site in range(294,315):\n",
    "                tm = '7'\n",
    "            else:\n",
    "                tm = 'CT/EC'                \n",
    "        \n",
    "        true_pos.append(str(trans_site))\n",
    "        aa.append(rows)\n",
    "        tmd.append(tm)\n",
    "true_pos.pop()\n",
    "aa.pop()\n",
    "tmd.pop()\n",
    "\n",
    "df['true_position'] = true_pos\n",
    "df['TMD'] = tmd\n",
    "df['amino_acid'] = aa\n",
    "df.to_csv(path_or_buf= os.path.join(report_dir,r'importance_report.csv'),index = 'Feature',mode=\"w\")\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe1c5b",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 5: Query the Model to Predict NEW Sequences</font> \n",
    "## Takes new sequences, inserts them into existing alignment to properly format for model query, then returns prediction of the λmax value for each sequence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05aff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from deepBreaks.utils import load_obj\n",
    "from deepBreaks.preprocessing import read_data\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from vpod_scripts.prediction_functions_db import process_sequences_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6da02",
   "metadata": {},
   "source": [
    "This is a version of the prediction method which can be used DIRECTLY after model training... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the mafft.bat file - change to your own directory!\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat'\n",
    "#path to sequences we want to add to an existing alignment in FASTA format\n",
    "input_file = './subtests/supp_test_data/msp_erg_raw.txt'\n",
    "#name for desired output file\n",
    "output_file = 'opsin_predictions.tsv'\n",
    "#path to target/selected model\n",
    "selected_model = report_dir + '/' + mtml[2] + '.pkl'\n",
    "#function for querying model - this will take care of creating an output file for you.\n",
    "process_sequences_from_file(mafft_exe,input_file,output_file,selected_model,seqFileName, gap_threshold=gap_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9890d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the mafft.bat file - change to your own directory!\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat'\n",
    "#path to sequences we want to add to an existing alignment in FASTA format\n",
    "input_file = './subtests/supp_test_data/msp_erg_raw.txt'\n",
    "#name for desired output file\n",
    "output_file = 'opsin_predictions.tsv'\n",
    "#path to target/selected model\n",
    "selected_model = report_dir + '/' + mtml[0] + '.pkl'\n",
    "#function for querying model - this will take care of creating an output file for you.\n",
    "process_sequences_from_file(mafft_exe,input_file,output_file,selected_model,seqFileName, gap_threshold=gap_threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBreaks_8_31_24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
