{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f4de42",
   "metadata": {},
   "source": [
    "# <font color=green>deepBreaks Applications</font>\n",
    "Modeling spectral tuning sites of opsin proteins based on amino-acid sequence...  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5b43e3c",
   "metadata": {},
   "source": [
    "# <font color=red>Step 0: Import libraries & open database</font>\n",
    "## The following imports the necessary libraries and opens the database (creating & filling it as necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65be46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os, re, datetime, subprocess, shutil, csv, sys\n",
    "from pathlib import Path\n",
    "# edit vpod_root_path to point to the project directory\n",
    "vpod_root_path = Path('../..').resolve()\n",
    "vpod_scripts_path = vpod_root_path/'scripts_n_notebooks'\n",
    "vpod_data_path = vpod_root_path/'vpod_data/VPOD_1.1'\n",
    "\n",
    "#we may or may not need to add the scripts path to the python path to import vpod_db\n",
    "try:\n",
    "    from vpod_db import init_db\n",
    "except:\n",
    "    sys.path.append(str(vpod_scripts_path))\n",
    "    from vpod_db import init_db\n",
    "\n",
    "db = init_db(vpod_data_path/'vizphiz.db',vpod_data_path/'raw_database_files')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6c27589",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 1: Extract Data Subsets From Vizphiz</font>\n",
    "### Output = 8 Different Data Subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory preperation\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seq_report_dir = str(f'vpod_1.1_data_splits_{dt_label}')\n",
    "os.makedirs(seq_report_dir)\n",
    "\n",
    "#declaring all variables for different sequence data subsets and their metadata\n",
    "wd_output = f'{seq_report_dir}/wds.txt'\n",
    "sws_output = f'{seq_report_dir}/uss.txt'\n",
    "mws_output = f'{seq_report_dir}/mls.txt'\n",
    "rod_output = f'{seq_report_dir}/rod.txt'\n",
    "wd_ni_output = f'{seq_report_dir}/vert.txt'\n",
    "inv_output = f'{seq_report_dir}/inv_only.txt'\n",
    "nmoc_output = f'{seq_report_dir}/wt.txt'\n",
    "mut_output = f'{seq_report_dir}/mut_only.txt'\n",
    "wh_metadata = f'{seq_report_dir}/wds_meta.tsv'\n",
    "sw_metadata = f'{seq_report_dir}/uss_meta.tsv'\n",
    "mw_metadata = f'{seq_report_dir}/mls_meta.tsv'\n",
    "rh_metadata = f'{seq_report_dir}/rod_meta.tsv'\n",
    "wd_ni_metadata = f'{seq_report_dir}/vert_meta.tsv'\n",
    "inv_metadata = f'{seq_report_dir}/inv_meta.tsv'\n",
    "nmoc_metadata = f'{seq_report_dir}/wt_meta.tsv'\n",
    "mut_metadata = f'{seq_report_dir}/mut_meta.tsv'\n",
    "\n",
    "#Setting the names for the headers at the top of each metadata file\n",
    "meta_data_list = [wh_metadata,sw_metadata,mw_metadata,rh_metadata,wd_ni_metadata,inv_metadata,nmoc_metadata,mut_metadata]\n",
    "meta_first_line = \"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tPhylum\\tClass\\tAccession\\tMutations\\nBovine\\t500.0000\\tBos_tarus\\tRh1\\tChordata\\tMammalia\\tNM_001014890\\n\"\n",
    "invert_first_line = \"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tPhylum\\tClass\\tAccession\\tMutations\\nSquid\\t473.0000\\tTodarodes_pacificus\\tRh1\\tMollusca\\tCephalopoda\\tX70498\\n\"\n",
    "bovine_seq = \">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\"\n",
    "\n",
    "#misc int variales for the counting loops\n",
    "m = 0\n",
    "s = 0\n",
    "l = 0\n",
    "r = 0\n",
    "c = 0\n",
    "z = 0\n",
    "q = 0\n",
    "mut = 0\n",
    "\n",
    "#regular expressions for filtering different opsin family types \n",
    "rod = re.compile('Rh[0-2]|exoRh')\n",
    "d = re.compile(\"^NM_001014890.2$|^NM_001014890$|^P02699.1$\")\n",
    "sws_reg = re.compile('^SWS')\n",
    "uvs_reg = re.compile('^UVS')\n",
    "mws_reg = re.compile('^MWS')\n",
    "lws_reg = re.compile('^LWS')\n",
    "rh1_reg = re.compile('^Rh[0-1]|exoRh')\n",
    "rh2_reg = re.compile('^Rh2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = db.cursor()\n",
    "\n",
    "sql = 'SELECT DISTINCT o.genus,o.species,o.genefamily,o.accession,h.lamdamax,o.aa,o.phylum,o.class,h.mutations FROM opsins o, heterologous h WHERE (o.accession = h.accession AND o.refid = h.refid);'\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "\n",
    "for x in myresult:  \n",
    "\n",
    "  if (x[4] == 0):\n",
    "    pass   \n",
    "  else:  \n",
    "  #SEQUENCE-DATA SECTION\n",
    "    #whole-dataset    \n",
    "    with open(wd_output, 'a') as f:\n",
    "      if m == 0:\n",
    "          f.write(bovine_seq)\n",
    "      if (d.match(x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        m += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(m)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    #vertebrate dataset\n",
    "    with open(wd_ni_output, 'a') as f:\n",
    "      if x[6] != \"Chordata\" or d.match(x[3]):\n",
    "        pass\n",
    "      else:\n",
    "        if c == 0:\n",
    "          f.write(bovine_seq)\n",
    "        c += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(c)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    #invertebrate dataset\n",
    "    with open(inv_output, 'a') as f:\n",
    "      if (x[6] != \"Chordata\"):\n",
    "        if q == 0:\n",
    "          f.write(\">Squid\\nMGRDLRDNETWWYNPSIVVHPHWREFDQVPDAVYYSLGIFIGICGIIGCGGNGIVIYLFTKTKSLQTPANMFIINLAFSDFTFSLVNGFPLMTISCFLKKWIFGFAACKVYGFIGGIFGFMSIMTMAMISIDRYNVIGRPMAASKKMSHRRAFIMIIFVWLWSVLWAIGPIFGWGAYTLEGVLCNCSFDYISRDSTTRSNILCMFILGFFGPILIIFFCYFNIVMSVSNHEKEMAAMAKRLNAKELRKAQAGANAEMRLAKISIVIVSQFLLSWSPYAVVALLAQFGPLEWVTPYAAQLPVMFAKASAIHNPMIYSVSHPKFREAISQTFPWVLTCCQFDDKETEDDKDAETEIPAGESSDAAPSADAAQMKEMMAMMQKMQQQQAAYPPQGYAPPPQGYPPQGYPPQGYPPQGYPPQGYPPPPQGAPPQGAPPAAPPQGVDNQAYQA\\n\")\n",
    "        q += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(q)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "      else:\n",
    "        pass\n",
    "    \n",
    "    #wild-type dataset\n",
    "    with open(nmoc_output, 'a') as f:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        if z == 0:\n",
    "          f.write(bovine_seq)\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:\n",
    "          z += 1 \n",
    "          #This makes the fasta format file\n",
    "          seq = \">S\" + str(z)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "\n",
    "    #just mutants dataset\n",
    "    with open(mut_output, 'a') as f:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        if mut == 0:\n",
    "          f.write(bovine_seq)\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:\n",
    "          mut += 1 \n",
    "          #This makes the fasta format file\n",
    "          seq = \">M\" + str(mut)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "      else:\n",
    "        pass\n",
    "    \n",
    "    #UVS and SWS dataset\n",
    "    with open(sws_output, 'a') as f:\n",
    "      p = re.compile('^SWS|^UVS')\n",
    "      if p.match(x[2]) and x[6] == \"Chordata\":\n",
    "        s+=1\n",
    "        if s == 1:\n",
    "          f.write(bovine_seq)\n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(s)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    #MWS and LWS dataset\n",
    "    with open(mws_output, 'a') as f:\n",
    "      p = re.compile('^MWS|^LWS')\n",
    "      if p.match(x[2]) and x[6] == \"Chordata\":\n",
    "        l+=1\n",
    "        if l == 1:\n",
    "          f.write(bovine_seq)\n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(l)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    #rods dataset\n",
    "    with open(rod_output, 'a') as f:\n",
    "      p = re.compile('Rh[0-2]|exoRh')\n",
    "      if p.match(x[2]):\n",
    "        if r == 0:\n",
    "          f.write(bovine_seq)\n",
    "        if (x[6] != \"Chordata\") or d.match(x[3]):\n",
    "          pass\n",
    "        else:\n",
    "          r+=1\n",
    "          #This makes the fasta format file\n",
    "          seq = \">S\" + str(r)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "\n",
    "  #METADATA SECTION - same idea and naming convention for the files as above. \n",
    "    with open(wh_metadata, 'a') as g:\n",
    "      if m == 1:\n",
    "          g.write(meta_first_line)      \n",
    "      if (d.match(x[3])):\n",
    "        pass\n",
    "      else:        \n",
    "        md =  str(\"S\" + str(m) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(wd_ni_metadata, 'a') as g:\n",
    "      if x[6] != \"Chordata\" or d.match(x[3]):\n",
    "        pass\n",
    "      else:\n",
    "        if c == 1:\n",
    "          g.write(meta_first_line)      \n",
    "\n",
    "        md =  str(\"S\" + str(c) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(inv_metadata, 'a') as g:\n",
    "      if (x[6] != \"Chordata\"):\n",
    "        if q == 1:\n",
    "          g.write(invert_first_line)\n",
    "        md =  str(\"S\" + str(q) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "      else:\n",
    "        pass\n",
    "          \n",
    "    with open(sw_metadata, 'a') as g:\n",
    "      p = re.compile('^SWS|^UVS')\n",
    "      if p.match(x[2]) and x[6] == \"Chordata\":\n",
    "        if s == 1:\n",
    "          g.write(meta_first_line)\n",
    "        md =  str(\"S\" + str(s) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(mw_metadata, 'a') as g:\n",
    "      p = re.compile('^MWS|^LWS')\n",
    "      if p.match(x[2]) and x[6] == \"Chordata\":\n",
    "        if l == 1:\n",
    "          g.write(meta_first_line)        \n",
    "        md =  str(\"S\" + str(l) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(rh_metadata, 'a') as g:\n",
    "      p = re.compile('Rh[0-3]|exoRh')\n",
    "\n",
    "      if p.match(x[2]):\n",
    "        if r == 1:\n",
    "          g.write(meta_first_line)      \n",
    "        if (x[6] != \"Chordata\") or d.match(x[3]):\n",
    "          pass\n",
    "        else:  \n",
    "          md =  str(\"S\" + str(r) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "\n",
    "    with open(nmoc_metadata, 'a') as g:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        if z == 1:\n",
    "          g.write(meta_first_line)      \n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:        \n",
    "          md =  str(\"S\" + str(z) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "\n",
    "    with open(mut_metadata, 'a') as g:\n",
    "      #p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if ((len(x[8]) > 1) or ('-' in x[3] and '_(' not in x[3])):\n",
    "        if mut == 1:\n",
    "          g.write(meta_first_line)      \n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:        \n",
    "          md =  str(\"M\" + str(mut) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','')  + \"\\t\" + str(x[2]).strip() + \"\\t\" + str(x[6]).strip() +\"\\t\" + str(x[7]).strip().replace(' ','') + '\\t' + x[3].strip() + \"\\t\" + str(x[8]).strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "      else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an additional sequence file where all the mutants are \n",
    "#added to the bottom of the wild-type sequences so they can be aligned for WT model test.\n",
    "with open(mut_output,'r') as f:\n",
    "  mut_only = f.readlines()\n",
    "mut_nmoc = f'{seq_report_dir}/wt_mut_added.txt'\n",
    "shutil.copy(nmoc_output , mut_nmoc)\n",
    "x = 0\n",
    "for lines in mut_only:\n",
    "  if x <= 1:\n",
    "    if x == 0:\n",
    "      with open(mut_nmoc, 'a') as m:\n",
    "        m.write('\\n')\n",
    "    else:\n",
    "      pass\n",
    "    x+=1\n",
    "  else:\n",
    "    with open(mut_nmoc, 'a') as m:\n",
    "      m.write(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "261d0aca",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 2: Align Raw Data w/MAFFT and Format for 'deepBreaks'</font>\n",
    "## REMINDER - You will need to change the directory for the 'mafft_exe' variable to the one of your own operating system!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import MafftCommandline\n",
    "from Bio import AlignIO\n",
    "\n",
    "data_split_list = [wd_output,sws_output,mws_output,rod_output,wd_ni_output,inv_output,nmoc_output,mut_nmoc,mut_output]\n",
    "output_list = []\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat' \n",
    "\n",
    "for data in data_split_list:\n",
    "    output = f'{data.split(\".\")[0]}.{data.split(\".\")[1]}_aligned.txt'\n",
    "    mafft_cline = MafftCommandline(mafft_exe, input=f'./{data}')\n",
    "    #print(mafft_cline)\n",
    "    stdout, stderr = mafft_cline()\n",
    "\n",
    "    with open(output, \"w\") as handle:\n",
    "        handle.write(stdout)\n",
    "        #print(handle)\n",
    "    align = AlignIO.read(output, \"fasta\")\n",
    "    output_list.append(f'{output}')\n",
    "\n",
    "    print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e914c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enters list of aligned text files here.\n",
    "inputs = output_list\n",
    "deep_breaks_input_data = []\n",
    "\n",
    "i=0\n",
    "k = 0\n",
    "for item in inputs:\n",
    "    print(item)\n",
    "    lines = open(inputs[i]).readlines()\n",
    "    output = f'{data.split(\".\")[0]}.{data.split(\".\")[1]}_aligned.txt'\n",
    "    deep_breaks_input_data.append(output)\n",
    "    print(output)\n",
    "    file = open(output, 'w')\n",
    "    m=0\n",
    "    for line in lines:\n",
    "        snip = str(lines[k])\n",
    "        if '>' in snip:\n",
    "            if m == 0:\n",
    "                m+=1\n",
    "            else:\n",
    "                file.write(\"\\n\")\n",
    "            file.write(snip)\n",
    "        else:\n",
    "            entry = \"\"\n",
    "            entry = str(snip.replace(\"\\n\",\"\"))\n",
    "            file.write(entry)\n",
    "        k+=1\n",
    "    k = 0\n",
    "    i+=1\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deep_breaks_input_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2969791",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 3: deepBreaks</font>\n",
    "## THIS IS A LONG SECTION! \n",
    "### **Output** = folder containing all results from model training, including comparison of model performances, an amino-acid site importance report + figures, and the top 5 trained models in a .pkl file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eed2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils import get_models, get_scores, get_params, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from deepBreaks.models import model_compare_cv, finalize_top, importance_from_pipe, mean_importance, summarize_results\n",
    "from deepBreaks.visualization import plot_scatter, dp_plot, plot_imp_model, plot_imp_all\n",
    "from deepBreaks.preprocessing import write_fasta\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "#assign your path to folder containing all the datasplits\n",
    "path = './vpod_1.1_data_splits_2024-05-02_16-58-09'\n",
    "# path to sequences of interest\n",
    "seqFileName = f'{path}/wds_aligned_VPOD_1.1_het.fasta' \n",
    "# path to corresponding metadata of interest\n",
    "metaDataFileName = f'{path}/wds_meta.tsv' \n",
    "\n",
    "# name of the phenotype\n",
    "mt = 'Lambda_Max'\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'reg' \n",
    "\n",
    "gap_threshold = 0.60\n",
    "\n",
    "#Whether or not you want to drop the reference sequence from the training data- Usually 'Bovine' or 'Squid'\n",
    "drop_ref = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a unique directory for saving the reports of the analysis\n",
    "print('direcory preparation')\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seqFile = seqFileName.split('/')[2]\n",
    "#print(seqFile)\n",
    "seqFile = seqFile.split('.')[0]\n",
    "#print(seqFile)\n",
    "report_dir = str(seqFile +'_' + mt + '_' + dt_label)\n",
    "os.makedirs(report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0ba03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print('reading meta-data')\n",
    "# importing metadata\n",
    "meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "# importing sequences data\n",
    "print('reading fasta file')\n",
    "\n",
    "tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=gap_threshold)\n",
    "\n",
    "shutil.copy2(f'{seqFileName}',report_dir)\n",
    "write_fasta(dat = tr, fasta_file = f'{seqFile}_gap_dropped.fasta' , report_dir = report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reference_seq = tr.loc['Bovine'].copy()\n",
    "    ref_seq_name = 'bovine'\n",
    "    if drop_ref == True:\n",
    "        meta_data = meta_data.drop('Bovine')\n",
    "    #print(bovine)\n",
    "except:\n",
    "    reference_seq = tr.loc['Squid'].copy()\n",
    "    ref_seq_name = 'squid'\n",
    "    #print(squid)\n",
    "reference_seq.to_csv(path_or_buf= f'{report_dir}/ref_sequence.csv',index = True,mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tr.loc[:, mt].values\n",
    "tr.drop(mt, axis=1, inplace=True)\n",
    "print('Shape of data is: ', tr.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69979653",
   "metadata": {},
   "source": [
    "**Attention**: metadata and sequences data should have the names as their row names and for each sequence their must be a value in the meta data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('metadata looks like this:')\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sequence data looks like this:')\n",
    "tr.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "140f567b",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "In this step, we do all these steps:\n",
    "1. dropping columns with a number of missing values above a certain threshold  \n",
    "2. dropping zero entropy columns  \n",
    "3. imputing missing values with the mode of that column  \n",
    "4. replacing cases with a frequency below a threshold (default 1.5%) with the mode of that column\n",
    "5. dropping zero entropy columns\n",
    "6. use statistical tests (each position against the phenotype) and drop columns with p-values below a threshold (default 0.25)\n",
    "7. one-hot encode the remaining columns\n",
    "8. calculate the pair-wise distance matrix for all of the columns\n",
    "9. use the distance matrix for DBSCAN and cluster the correlated positions together\n",
    "10. keep only one column (closes to center of each cluster) for each group and drop the rest from the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.025)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=False)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.001, keep=False))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "report, top = model_compare_cv(X=tr, y=y, preprocess_pipe=prep_pipeline,\n",
    "                               models_dict=get_models(ana_type=ana_type),\n",
    "                               scoring=get_scores(ana_type=ana_type),\n",
    "                               report_dir=report_dir,\n",
    "                               cv=15, ana_type=ana_type, cache_dir=report_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af902297",
   "metadata": {},
   "source": [
    "MAE = Mean Absolute Error\n",
    "\n",
    "MSE = Mean Squared Error\n",
    "\n",
    "RMSE = Rooted Mean Square Error\n",
    "\n",
    "MAPE = Mean Absolute % Error - the average magnitude of error produced by a model, or how far off predictions are on average. A MAPE value of 20% means that the average absolute percentage difference between the predictions and the actuals is 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.025)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=True)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.001, keep=True))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df108475",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top = []\n",
    "mtml = []\n",
    "for model in top:\n",
    "    modified_top.append(make_pipeline(steps=[('prep', prep_pipeline), model.steps[-1]]))\n",
    "    my_top_models = str(model[1:])\n",
    "    #print(my_top_models)\n",
    "    my_top_models = my_top_models.split(\"'\")[3]\n",
    "    mtml.append(my_top_models)\n",
    "    #print(my_top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7005603",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top = finalize_top(X=tr, y=y, top_models=modified_top, grid_param=get_params(),report_dir=report_dir, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sr = summarize_results(top_models=top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bce71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot = plot_scatter(summary_result=sr, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_imp = mean_importance(top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e644ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_plot(importance=mean_imp,imp_col='mean', model_name='mean', report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ed0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = prep_pipeline[:4].fit_transform(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in top:\n",
    "    model_name = model.steps[-1][0]\n",
    "    dp_plot(importance=importance_from_pipe(model),\n",
    "            imp_col='standard_value',\n",
    "            model_name = model_name, report_dir=report_dir)\n",
    "    \n",
    "    plot_imp_model(importance=importance_from_pipe(model), \n",
    "               X_train=tr, y_train=y, model_name=model_name,\n",
    "                   meta_var='meta', model_type=ana_type, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = plot_imp_all(final_models=top,\n",
    "                  X_train=tr, y_train=y,\n",
    "                  model_type = ana_type,\n",
    "                  report_dir=report_dir, max_plots=100,\n",
    "                  figsize=(2.5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepBreaks.utils import load_obj\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ae400",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_per_mod = report_dir + '/' + mtml[0] + '.pkl'\n",
    "load_top_mod = load_obj(top_per_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c553a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Here is a list of your top performing models to test...\\n{mtml}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08805113",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 4: Translate Candidate STSs</font> \n",
    "## This section is used to translate candidate STSs to the bovine or squid equivalent.\n",
    "### The bovine and squid sequence dataframes that were saved earlier and are called again here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: Translate Candidate STSs \n",
    "#translate candidate STSs to the bovine or squid equivalent \n",
    "#bovine and squid sequence dataframes were saved earlier and are called again here\n",
    "m = 0\n",
    "tm = ''\n",
    "k=0\n",
    "gaps=0\n",
    "#import importance_report.csv from report_dir\n",
    "true_pos = []\n",
    "aa = []\n",
    "tmd = []\n",
    "df = pd.read_csv(f'{report_dir}\\importance_report.csv')\n",
    "#take the list of important sites and translate them to the bovine standard equivalent, \n",
    "#we do this by taking the site number and subtracting the number of '-' between the start of the sequence and the desired site. \n",
    "for rows in reference_seq.values:  \n",
    "    rows = str(rows)\n",
    "    #print(rows)\n",
    "    if rows == 'nan':\n",
    "    #We want to write the 'true_pos', 'aa', and 'TMD' to the 'importance_report' csv file\n",
    "        gaps += 1\n",
    "        k += 1\n",
    "        true_pos.append('NA')\n",
    "        aa.append('-')\n",
    "        tmd.append('NA')\n",
    "    else:\n",
    "        #print(\"The number of gaps is \" + str(gaps))\n",
    "        k+=1\n",
    "        trans_site = k - gaps\n",
    "        if ref_seq_name == 'bovine':\n",
    "            if trans_site in range(3,37):\n",
    "                tm = 'N-Termina'\n",
    "            elif trans_site in range(37,62):\n",
    "                tm = '1'\n",
    "            elif trans_site in range(74,96):\n",
    "                tm = '2'\n",
    "            elif trans_site in range(111,133):\n",
    "                tm = '3'\n",
    "            elif trans_site in range(153,174):\n",
    "                tm = '4'\n",
    "            elif trans_site in range(203,225):\n",
    "                tm = '5'\n",
    "            elif trans_site in range(253,275):\n",
    "                tm = '6'\n",
    "            elif trans_site in range(287,309):\n",
    "                tm = '7'\n",
    "            else:\n",
    "                tm = 'CT/EC'\n",
    "        else:\n",
    "            if trans_site in range(3,34):\n",
    "                tm = 'N-Termina'\n",
    "            elif trans_site in range(34,59):\n",
    "                tm = '1'\n",
    "            elif trans_site in range(71,97):\n",
    "                tm = '2'\n",
    "            elif trans_site in range(110,132):\n",
    "                tm = '3'\n",
    "            elif trans_site in range(152,173):\n",
    "                tm = '4'\n",
    "            elif trans_site in range(200,225):\n",
    "                tm = '5'\n",
    "            elif trans_site in range(262,284):\n",
    "                tm = '6'\n",
    "            elif trans_site in range(294,315):\n",
    "                tm = '7'\n",
    "            else:\n",
    "                tm = 'CT/EC'                \n",
    "        \n",
    "        true_pos.append(str(trans_site))\n",
    "        aa.append(rows)\n",
    "        tmd.append(tm)\n",
    "true_pos.pop()\n",
    "aa.pop()\n",
    "tmd.pop()\n",
    "\n",
    "df['true_position'] = true_pos\n",
    "df['TMD'] = tmd\n",
    "df['amino_acid'] = aa\n",
    "df.to_csv(path_or_buf= os.path.join(report_dir,r'importance_report.csv'),index = 'Feature',mode=\"w\")\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe1c5b",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 5: Query the Model to Predict NEW Sequences</font> \n",
    "## Takes new sequences, inserts them into existing alignment to properly format for model query, then returns prediction of the Î»max value for each sequence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05aff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from deepBreaks.utils import load_obj\n",
    "from deepBreaks.preprocessing import read_data\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from vpod_scripts.prediction_functions_db import process_sequences_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6da02",
   "metadata": {},
   "source": [
    "This is a version of the prediction method which can be used DIRECTLY after model training... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the mafft.bat file - change to your own directory!\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat'\n",
    "#path to sequences we want to add to an existing alignment in FASTA format\n",
    "input_file = './subtests/supp_test_data/msp_erg_raw.txt'\n",
    "#name for desired output file\n",
    "output_file = 'opsin_predictions.tsv'\n",
    "#path to target/selected model\n",
    "selected_model = report_dir + '/' + mtml[0] + '.pkl'\n",
    "#function for querying model - this will take care of creating an output file for you.\n",
    "process_sequences_from_file(mafft_exe,input_file,output_file,selected_model,seqFileName,gap_threshold=gap_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da102e",
   "metadata": {},
   "source": [
    "This is a version of the prediction method which can be used to ACCESS EXISTING MODELS in a SEPERATE SESSION after model training... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f269fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the mafft.bat file - change to your own directory!\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat'\n",
    "#path to sequences we want to add to an existing alignment in FASTA format\n",
    "input_file = './subtests/supp_test_data/msp_erg_raw.txt'\n",
    "#name for desired output file\n",
    "output_file = 'opsin_predictions.tsv'\n",
    "#path to the primary alignment used for training the model - if trying access a specific file later\n",
    "path = 'c:/Users/safra/Documents/GitHub/visual-physiology-opsin-db/vpod_data/VPOD_1.0/formatted_data_subsets/vpod_2023-10-16_12-13-11'\n",
    "seqFileName = f'{path}/VPOD_wds_het_1.0.fasta' \n",
    "#path to target/selected model\n",
    "#can use method below or enter path manually if coming back to notebook with no variables intialized\n",
    "report_dir ='C:/Users/safra/Documents/GitHub/visual-physiology-opsin-db/result_files/main_model_results/mafft/wds_model_2023-10-16_12-13-40'\n",
    "selected_model = report_dir + '/gbc.pkl'\n",
    "#function for querying model - this will take care of creating an output file for you.\n",
    "process_sequences_from_file(mafft_exe,input_file,output_file,selected_model,seqFileName,gap_threshold=gap_threshold)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
