{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f4de42",
   "metadata": {},
   "source": [
    "# <font color=#c51b8a>deepBreaks Applications</font>\n",
    "### Modeling the phenotypes and spectral tuning sites of opsin proteins based on amino-acid sequence...  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5b43e3c",
   "metadata": {},
   "source": [
    "# <font color=c994c7>Step 0: VPOD Setup w/SQLite</font>\n",
    "### *The following function sets up the schema for our vizphiz database it doesn't yet exist. Otherwise it loads an existing version of VPOD stored locally.*\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "import re\n",
    "import os\n",
    "import datetime \n",
    "import subprocess\n",
    "import shutil \n",
    "import csv\n",
    "import fileinput\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit vpod_root_path to point to the project directory\n",
    "vpod_root_path = Path('../..').resolve()\n",
    "vpod_scripts_path = vpod_root_path/'scripts_n_notebooks'\n",
    "vpod_data_path = vpod_root_path/'vpod_data/VPOD_1.2'\n",
    "from vpod_scripts.vpod_db import init_db\n",
    "\n",
    "mydb = init_db(vpod_data_path/'vizphiz.db',vpod_data_path/'raw_database_files')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6c27589",
   "metadata": {},
   "source": [
    "# <font color=c994c7>Step 1a: Extract Heterolgous Data Subsets From VPOD</font>\n",
    " - Output = 9 Different Data Subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from vpod_scripts.extract_vpod_datasets import extract_vpod_datasets, get_mnm_datasets\n",
    "\n",
    "seq_report_dir, data_split_list, meta_data_list, mnm_meta_list, mnm_meta_shorthand = extract_vpod_datasets(mydb)\n",
    "print(f\"VPOD datasets extracted to: {seq_report_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05236da4",
   "metadata": {},
   "source": [
    "# <font color=c994c7>Step 1b: Create 'Inferred' Physiological Data Subsets From Mine-n-Match (MNM)</font>\n",
    "\n",
    "### These datasets Consider Physiology Data (i.e. Single-Cell Microspectrophotemtry Readings) in Combination With the Heterologus Data From VPOD\n",
    " - Output is 5 extra datasets marked 'mnm' in the same folder directory created above ^ ('i.e. - The 'wt_mnm_meta.csv' file contains VPOD's heterolgous and MNM data)\n",
    "\n",
    " - The MNM pipeline (which you can find in this same folder) connects sequence to it's closest MSP value based on OPTICS predictions (our command-line tool for predicting opsin lambda max)\n",
    " \n",
    " - For more information, read our publication - HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './mine_n_match/mnm_data/mnm_on_mnm_on_all_dbs_2025-02-24_16-29-54'\n",
    "mnm_file = f'{path}/mnm_on_vpod_acc_dbs_results_fully_filtered.csv'\n",
    "mnm_data = read_data(mnm_file, seq_type = None, is_main=False)\n",
    "# This function generates the 'mnm' datasets,\n",
    "# which are a combination of the VPOD 'het' datasets and the corresponding 'mnm' data\n",
    "data_split_list, meta_data_list = get_mnm_datasets(seq_report_dir, mnm_data, mnm_meta_list, mnm_meta_shorthand, meta_data_list, data_split_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "261d0aca",
   "metadata": {},
   "source": [
    "# <font color=#c994c7>Step 2: Align Raw Data w/MAFFT and Format for 'deepBreaks'</font>\n",
    "### REMINDER - You will need to change the directory for the 'mafft_exe' variable to the one of your own operating system!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vpod_scripts.extract_vpod_datasets import perform_mafft_alignment\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat' \n",
    "deep_breaks_input_data = perform_mafft_alignment(data_split_list, mafft_exe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2969791",
   "metadata": {},
   "source": [
    "# <font color=#c994c7>Step 3: deepBreaks</font>\n",
    "## THIS IS A LONG SECTION! \n",
    " - **Output** = folder containing all results from model training, including comparison of model performances, an amino-acid site importance report + figures, and the top 5 trained models in a .pkl file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eed2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing deepBreaks libraries \n",
    "from vpod_scripts.deepBreaks.utils_alt2 import get_models, get_best_aa_prop_combos, get_scores, get_params, get_empty_params, make_pipeline\n",
    "from vpod_scripts.deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder, AminoAcidPropertyEncoder\n",
    "from vpod_scripts.deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from vpod_scripts.deepBreaks.preprocessing import read_data\n",
    "from vpod_scripts.deepBreaks.models import model_compare_cv, finalize_top, importance_from_pipe, aaprop_importance_from_pipe,  mean_importance, summarize_results\n",
    "from vpod_scripts.deepBreaks.visualization import plot_scatter, dp_plot, dp_aa_prop_plot, plot_imp_model, plot_imp_all\n",
    "from vpod_scripts.deepBreaks.preprocessing import write_fasta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "# assign your path to folder containing all the datasplits\n",
    "#path = './vpod_1.2_data_splits_2025-02-28_15-51-04'\n",
    "path = f'./{seq_report_dir}'\n",
    "\n",
    "# path to sequences of interest\n",
    "seqFileName = f'{path}/wds_mnm_aligned_VPOD_1.2_het.fasta' \n",
    "\n",
    "# path to corresponding metadata of interest\n",
    "metaDataFileName = f'{path}/wds_mnm_meta.csv' \n",
    "# only put dataset name if you want the grid-search p[timizerd models.\n",
    "# otherwise, leave as 'ignore'\n",
    "dataset = 'wds_mnm'\n",
    "use_gs_params = False\n",
    "\n",
    "# name of the phenotype\n",
    "mt = 'Lambda_Max'\n",
    "\n",
    "# If true, train models using electron-volts (ev) instead of normal wavelength (nm) values.\n",
    "use_ev = False\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'reg' \n",
    "\n",
    "# Proportion of gaps at an amino acid site alloable in an alignment before dropping column completely\n",
    "gap_threshold = 0.5\n",
    "\n",
    "# Whether or not you want to drop the reference sequence from the training data- Usually 'Bovine' or 'Squid'\n",
    "drop_ref = False\n",
    "\n",
    "# Methos of encoding opsin sequences - Options: One-Hot-Encoding ('hot') or Amino-Acid Property Encoding ('aa_prop')\n",
    "encoding_method='aa_prop'\n",
    "use_best_props=True\n",
    "# Specify which properties you want to keep for the amino-acid property encoding:\n",
    "# We keep FIVE by deafult - 'H1, H3, P1, NCI, MASS' \n",
    "# But ELEVEN total are avaliable -'H1, H2, H3, P1, P2, V, NCI, MASS, SASA, PKA, PKB and SCT' \n",
    "# If you want to keep ALL aa props, just set props_to_keep = 'all'\n",
    "# Or specify the properties in list format props_to_keep = ['H1', 'H3', 'P1', 'NCI', 'MASS']\n",
    "# Only need to worry about this if encoding_method == 'aa_prop'\n",
    "if use_best_props == True:\n",
    "    props_to_keep = get_best_aa_prop_combos(dataset)\n",
    "else:\n",
    "    props_to_keep = ['H1', 'H3', 'NCI']\n",
    "\n",
    "if use_gs_params == False:\n",
    "    dataset='ignore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a unique directory for saving the reports of the analysis\n",
    "print('direcory preparation')\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seqFile = seqFileName.split('/')[2]\n",
    "#print(seqFile)\n",
    "seqFile = seqFile.split('.')[0]+'.'+seqFile.split('.')[1]\n",
    "#print(seqFile)\n",
    "if encoding_method == 'hot':\n",
    "    report_dir = str(seqFile +'_' + mt + '_' + dt_label)\n",
    "elif encoding_method == 'aa_prop':\n",
    "    props_used = ''\n",
    "    for props in props_to_keep:\n",
    "        props_used += props + '_'\n",
    "    report_dir = str(props_used + seqFile +'_' + mt + '_' + dt_label)\n",
    "os.makedirs(report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0ba03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print('reading meta-data')\n",
    "# importing metadata\n",
    "meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "# importing sequences data\n",
    "print('reading fasta file')\n",
    "\n",
    "tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=gap_threshold)\n",
    "\n",
    "shutil.copy2(f'{seqFileName}',report_dir)\n",
    "write_fasta(dat = tr, fasta_file = f'{seqFile}_gap_dropped.fasta' , report_dir = report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reference_seq = tr.loc['Bovine'].copy()\n",
    "    ref_seq_name = 'bovine'\n",
    "    if drop_ref == True:\n",
    "        meta_data = meta_data.drop('Bovine')\n",
    "    #print(bovine)\n",
    "except:\n",
    "    reference_seq = tr.loc['Squid'].copy()\n",
    "    ref_seq_name = 'squid'\n",
    "    #print(squid)\n",
    "reference_seq.to_csv(path_or_buf= f'{report_dir}/ref_sequence.csv',index = True,mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tr.loc[:, mt].values\n",
    "if use_ev == True:\n",
    "    y = 1239.8 / np.array(y)\n",
    "tr.drop(mt, axis=1, inplace=True)\n",
    "print('Shape of data is: ', tr.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69979653",
   "metadata": {},
   "source": [
    "**Attention**: metadata and sequences data should have the names as their row names and for each sequence their must be a value in the meta data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('metadata looks like this:')\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sequence data looks like this:')\n",
    "tr.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "140f567b",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "In this step, we do all these steps:\n",
    "1. dropping columns with a number of missing values above a certain threshold  \n",
    "2. dropping zero entropy columns  \n",
    "3. imputing missing values with the mode of that column  \n",
    "4. replacing cases with a frequency below a threshold (default 1.5%) with the mode of that column\n",
    "5. dropping zero entropy columns\n",
    "6. use statistical tests (each position against the phenotype) and drop columns with p-values below a threshold (default 0.25)\n",
    "7. one-hot encode the remaining columns\n",
    "8. calculate the pair-wise distance matrix for all of the columns\n",
    "9. use the distance matrix for DBSCAN and cluster the correlated positions together\n",
    "10. keep only one column (closes to center of each cluster) for each group and drop the rest from the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoding_method == 'hot': \n",
    "    prep_pipeline = make_pipeline(\n",
    "        steps=[\n",
    "            ('mc', MisCare(missing_threshold=0.05)),\n",
    "            ('cc', ConstantCare()),\n",
    "            ('ur', URareCare(threshold=0.01)),\n",
    "            ('cc2', ConstantCare()),\n",
    "            ('one_hot', CustomOneHotEncoder()),\n",
    "            ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=False)),\n",
    "            ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=False))\n",
    "            \n",
    "        ])\n",
    "elif encoding_method == 'aa_prop':\n",
    "    prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('aa_prop', AminoAcidPropertyEncoder(props_to_keep = props_to_keep)),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=False)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=False))\n",
    "    ])\n",
    "else:\n",
    "    raise ValueError('Encoding method not recognized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "report, top = model_compare_cv(X=tr, y=y, preprocess_pipe=prep_pipeline,\n",
    "                               models_dict=get_models(ana_type=ana_type, encoding=encoding_method, dataset=dataset),\n",
    "                               scoring=get_scores(ana_type=ana_type),\n",
    "                               report_dir=report_dir,\n",
    "                               cv=10, ana_type=ana_type, cache_dir=report_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af902297",
   "metadata": {},
   "source": [
    "MAE = Mean Absolute Error\n",
    "\n",
    "MSE = Mean Squared Error\n",
    "\n",
    "RMSE = Rooted Mean Square Error\n",
    "\n",
    "MAPE = Mean Absolute % Error - the average magnitude of error produced by a model, or how far off predictions are on average. A MAPE value of 20% means that the average absolute percentage difference between the predictions and the actuals is 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoding_method == 'hot':\n",
    "    prep_pipeline = make_pipeline(\n",
    "        steps=[\n",
    "            ('mc', MisCare(missing_threshold=0.05)),\n",
    "            ('cc', ConstantCare()),\n",
    "            ('ur', URareCare(threshold=0.025)),\n",
    "            ('cc2', ConstantCare()),\n",
    "            ('one_hot', CustomOneHotEncoder()),\n",
    "            ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=True)),\n",
    "            ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=True))\n",
    "        ])\n",
    "elif encoding_method == 'aa_prop':\n",
    "    prep_pipeline = make_pipeline(\n",
    "        steps=[\n",
    "            ('mc', MisCare(missing_threshold=0.05)),\n",
    "            ('cc', ConstantCare()),\n",
    "            ('aa_prop', AminoAcidPropertyEncoder(props_to_keep = props_to_keep)),\n",
    "            ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=True)),\n",
    "            ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=True))\n",
    "        ])\n",
    "else:\n",
    "    raise ValueError('Encoding method not recognized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df108475",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top = []\n",
    "mtml = []\n",
    "for model in top:\n",
    "    modified_top.append(make_pipeline(steps=[('prep', prep_pipeline), model.steps[-1]]))\n",
    "    my_top_models = str(model[1:])\n",
    "    my_top_models = my_top_models.split(\"'\")[3]\n",
    "    mtml.append(my_top_models)\n",
    "    #print(my_top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7005603",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top = finalize_top(X=tr, y=y, top_models=modified_top, grid_param=get_empty_params(),report_dir=report_dir, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sr = summarize_results(top_models=top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bce71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot = plot_scatter(summary_result=sr, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_imp = mean_importance(top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e644ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoding_method == 'hot':\n",
    "    dp_plot(importance=mean_imp,imp_col='mean', model_name='mean', report_dir=report_dir)\n",
    "elif encoding_method == 'aa_prop':\n",
    "    dp_aa_prop_plot(importance=mean_imp,imp_col='mean', model_name='mean', report_dir=report_dir, props_to_keep = props_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_ev == False:\n",
    "    meta_var='位max (nm)'\n",
    "else:\n",
    "    meta_var='位max (eV)'\n",
    "    \n",
    "if encoding_method == 'hot':\n",
    "    tr_copy = tr.copy()\n",
    "    encoded_seqs = prep_pipeline[:4].fit_transform(tr)\n",
    "    for model in top:\n",
    "        model_name = model.steps[-1][0]\n",
    "        dp_plot(importance=importance_from_pipe(model),\n",
    "                imp_col='standard_value',\n",
    "                model_name = model_name, report_dir=report_dir)\n",
    "        \n",
    "        plot_imp_model(importance=importance_from_pipe(model), \n",
    "                X_train=encoded_seqs, y_train=y, model_name=model_name,\n",
    "                    meta_var=meta_var, model_type=ana_type, report_dir=report_dir)\n",
    "\n",
    "    pl = plot_imp_all(final_models=top,\n",
    "                    X_train=tr, y_train=y,\n",
    "                    model_type = ana_type,\n",
    "                    report_dir=report_dir, max_plots=350,\n",
    "                    figsize=(2.5, 3), meta_var=meta_var)\n",
    "elif encoding_method == 'aa_prop':\n",
    "    for model in top:\n",
    "        encoded_seqs = model.named_steps['prep']['aa_prop'].aa_encoded_seqs_\n",
    "        model_name = model.steps[-1][0]\n",
    "        \n",
    "        dp_aa_prop_plot(importance=aaprop_importance_from_pipe(model),\n",
    "                imp_col='standard_value',\n",
    "                model_name = model_name, report_dir=report_dir, props_to_keep = props_to_keep)\n",
    "        \n",
    "        plot_imp_model(importance=aaprop_importance_from_pipe(model), \n",
    "                X_train=encoded_seqs, y_train=y, model_name=model_name,\n",
    "                    meta_var='位max', model_type=ana_type, report_dir=report_dir)\n",
    "        \n",
    "    pl = plot_imp_all(final_models=top,\n",
    "                X_train=encoded_seqs, y_train=y,\n",
    "                model_type = ana_type,\n",
    "                report_dir=report_dir, max_plots=100,\n",
    "                figsize=(2.5, 3), meta_var=meta_var)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08805113",
   "metadata": {},
   "source": [
    "# <font color=#c994c7>Step 4: Translate Candidate Spectral Tuning Sites (STS)</font> \n",
    "### This section is used to translate candidate STS to the bovine or squid equivalent.\n",
    " - The bovine and squid sequence dataframes that were saved earlier and are called again here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vpod_scripts.translate_candidate_sts import translate_candidate_sts, translate_candidate_sts_aa_props\n",
    "\n",
    "if encoding_method == 'hot':\n",
    "    trans_imp_report = translate_candidate_sts(report_dir, ref_seq_name, reference_seq)\n",
    "elif encoding_method == 'aa_prop':\n",
    "    trans_imp_report = translate_candidate_sts_aa_props(report_dir, reference_seq, ref_seq_name)\n",
    "\n",
    "trans_imp_report.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dc777",
   "metadata": {},
   "source": [
    "# <font color=#c994c7>STEP 5: Query the Model to Predict NEW Sequences</font> \n",
    "### Takes new sequences, inserts them into existing alignment to properly format for model query, then returns prediction of the 位max value for each sequence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82eca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from deepBreaks.utils import load_obj\n",
    "from deepBreaks.preprocessing import read_data\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from vpod_scripts.prediction_functions import process_sequences_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dee0f5",
   "metadata": {},
   "source": [
    "This is a version of the prediction method which can be used DIRECTLY after model training... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the mafft.bat file - change to your own directory!\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat'\n",
    "#path to sequences we want to add to an existing alignment in FASTA format\n",
    "input_file = './subtests/supp_test_data/msp_erg_raw.txt'\n",
    "#name for desired output file\n",
    "output_file = f'{report_dir}/ex_opsin_predictions.tsv'\n",
    "#path to target/selected model\n",
    "selected_model = report_dir + '/' + mtml[0] + '.pkl'\n",
    "#function for querying model - this will take care of running predictions and creating an output file for you.\n",
    "predictions_df = process_sequences_from_file(mafft_exe,input_file,output_file,selected_model,seqFileName, gap_threshold=gap_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afe3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the meta-data file with our 'ground-truths'\n",
    "msp_meta_file = './subtests/supp_test_data/msp_erg_meta.tsv'\n",
    "msp_meta = read_data(msp_meta_file, seq_type = None, is_main=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Create scatter plot to visulize relationship between our predicted and 'true' lmax values...\n",
    "plt.scatter(msp_meta['Lambda_Max'], predictions_df['Predictions'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Model Predictions vs True Values')\n",
    "\n",
    "# Display plot\n",
    "plt.show()\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(msp_meta['Lambda_Max'], predictions_df['Predictions'])\n",
    "\n",
    "# Print R-squared\n",
    "print(f\"R-squared: {r2:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBreaks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
