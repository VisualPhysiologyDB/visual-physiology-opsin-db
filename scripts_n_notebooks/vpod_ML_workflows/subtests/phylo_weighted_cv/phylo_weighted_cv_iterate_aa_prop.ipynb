{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <font color=green>deepBreaks Application</font>\n",
    "\n",
    " Modeling the phenotypes and spectral tuning sites of opsin proteins based on amino-acid sequence..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color=red>Application Focus:</font>\n",
    "\n",
    " <font color=white>Phylogenetically Weighted Cross Validation Iteratative Testing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **What factors are we interested in observing the effects of on model performance?**\n",
    "\n",
    " * percentile threshold (aka - our desired minimum distance threshold)\n",
    "\n",
    " * relation_mode handeling methods (leave_out, max_mean, merge, random) - How to handle nodes which fall below the distance threshold\n",
    "\n",
    " * n_folds - How sensitive is this approach to differnt numbers of cross-validation folds?\n",
    "\n",
    " * tree models - How sensitive is this approach to different algorythms\n",
    "\n",
    "\n",
    "\n",
    " **What is the best way to loop through these conditions?**\n",
    "\n",
    " 1. For each tree in a folder of trees (each constructed using a different algorythm)\n",
    "\n",
    " 2. For each relation handeling method\n",
    "\n",
    " 3. For each n_folds in a range of fold numbers to test\n",
    "\n",
    " 4. For each percentile threshold in a range of desired thresholds to test\n",
    "\n",
    " 5. For each model algorythm in the deepBreaks pipeline\n",
    "\n",
    " [Each subsequent number is nested in the previous - so for one tree we do all forms of relation handeling - and for all forms of relation handeling we go through all of a selected range of cv fold sizes and then we go through all percentile thresholds  in a list of percentile thresholds]\n",
    "\n",
    "\n",
    "\n",
    " **What are the set paramaters or range of parameters we'll test as differnt conditions?**\n",
    "\n",
    " * Tree Models / Tree Used - [for WT opsins] LG+F+R7 (top model), Q.pfam+F+R7, WAG+F+R7 // [for WT vert opsins] LG+F+R6, Q.pfam+F+R6, WAG+F+R6\n",
    "\n",
    " * Relation Handeling Methods - leave_out, max_mean, merge, random\n",
    "\n",
    " * Number of Folds - [5,8,10,12,15,20]\n",
    "\n",
    " * Percentile Threshold Range - 1st -> 95th Percentiles - divied up into 40 percentile points in a list\n",
    "\n",
    " * Normal selection of models from first round of training (pre-grid-search)\n",
    "\n",
    "\n",
    "\n",
    " **General Workflow**\n",
    "\n",
    " * Read a folders contents [should only contain phylogentic trees to test] and select a phylogentic tree file\n",
    "\n",
    " * Load target phylogentic tree (_should be based on corresponding fasta file of sequence data_)\n",
    "\n",
    " * Create new folder speific to testing that phylogentic tree - can use the name as the basis for naming the new folder - including the date and time\n",
    "\n",
    " * Create either a new excel compatible csv file for recording the results of each test iteration or seperate excel files by number of folds, recording all upstream information about the test conditions in the file name and/or in some section of the excel/csv file. from each round of testing we should group results by Tree used (can be tree file name), then by relation handeling method, then by number of folds and then by model, and the corresponding R^2 value for a given threshold. (My end goal is to be able to graph all these different conditions).\n",
    "\n",
    " NOTE - Following each round of model training the results are recorded in a csv file named 'model_report.csv' - we'll need to extract the R^2 values for each model from that column. On the first run we'll aslo need to extract all the model names so we can add them to the results file where we're recording model performance vs. threshold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#loading neccessary vpod scripts for phylogenetic cross validation\n",
    "from vpod_scripts.phylo_weighted_cv import get_dist_matrix_from_tree, percentile_threshold, phylo_weighted_cv, plot_phylo_cv_line_graphs, plot_phylo_cv_indv_model_graphs, plot_phylo_cv_bar_graphs \n",
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils_alt2 import get_models, get_scores, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare, AminoAcidPropertyEncoder\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from deepBreaks.models import model_compare_cv\n",
    "from deepBreaks.preprocessing import write_fasta\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import shutil \n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "#assign your path to folder containing all the datasplits\n",
    "path = './vpod_1.2_data_splits_2024-10-19_10-30-09'\n",
    "# path to sequences of interest\n",
    "seqFileName = f'{path}/wt_mnm_aligned_VPOD_1.2_het.fasta' \n",
    "# path to corresponding metadata of interest\n",
    "metaDataFileName = f'{path}/wt_mnm_meta.csv' \n",
    "ds = 'wt'\n",
    "\n",
    "encoding = 'aa_prop'\n",
    "\n",
    "# name of the phenotype\n",
    "mt = 'Lambda_Max'\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'reg' \n",
    "\n",
    "gap_threshold = 0.5\n",
    "\n",
    "#Whether or not you want to drop the reference sequence from the training data- Either 'Bovine' or 'Squid' (for Invertebrate dataset)\n",
    "drop_ref = False\n",
    "\n",
    "#Specify which properties you want to keep for the amino-acid property encoding:\n",
    "#We keep FIVE by deafult - 'H1, H3, P1, NCI, MASS' \n",
    "#But NINE total are avaliable -'H1, H2, H3, P1, P2, V, NCI, MASS, and SASA' \n",
    "#If you want to keep ALL aa props, just set props_to_keep = 'all'\n",
    "# Or specify the properties in list format props_to_keep = ['H1', 'H3', 'P1', 'NCI', 'MASS']\n",
    "props_to_keep = ['H1', 'H3', 'NCI']\n",
    "\n",
    "# making a unique directory for saving the reports of the analysis\n",
    "#print('direcory preparation')\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seqFile = seqFileName.split('/')[2]\n",
    "#print(seqFile)\n",
    "seqFile = seqFile.split('.')[0]+ '.'+ seqFile.split('.')[1]\n",
    "#print(seqFile)\n",
    "props_used = ''\n",
    "for props in props_to_keep:\n",
    "    props_used += props + '_'\n",
    "report_dir = str(props_used + seqFile +'_' + mt + '_' + dt_label)\n",
    "os.makedirs(report_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#print('reading meta-data')\n",
    "# importing metadata\n",
    "meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "# importing sequences data\n",
    "#print('reading fasta file')\n",
    "\n",
    "tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=gap_threshold)\n",
    "\n",
    "shutil.copy2(f'{seqFileName}',report_dir)\n",
    "write_fasta(dat = tr, fasta_file = f'{seqFile}_gap_dropped.fasta' , report_dir = report_dir)\n",
    "\n",
    "tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Parameters and Conditions to Test\n",
    "relation_handling_methods = [\"leave_out\", \"merge\", \"max_mean\", \"random\"]\n",
    "n_folds_range = [5, 8, 10, 12, 15, 20]\n",
    "percentile_threshold_range = list(range(1, 96, int(95 / 40))) # Generate 40 percentile points\n",
    "tree_folder = \"./phylo_cv_results/opsin_vert_wt_tree/vpod_1.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Create prep_pipeline outside the loop to avoid re-creation\n",
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('aa_prop', AminoAcidPropertyEncoder(props_to_keep = props_to_keep)),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=False)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=False))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "for tree_file in os.listdir(tree_folder):\n",
    "    if tree_file.endswith(\".treefile\"): # Process only tree files\n",
    "        # Load phylogenetic tree and obtain pair-wise distance matrix\n",
    "        tree_path = os.path.join(tree_folder, tree_file)\n",
    "        dist_matrix, tip_names = get_dist_matrix_from_tree(tree_path)\n",
    "        \n",
    "        # Create new folder for results\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        results_folder = f\"{tree_file.split('.')[0]}.{tree_file.split('.')[1]}_phylo_cv_{timestamp}\"\n",
    "        os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "        # Create results file (choose CSV or Excel based on your preference)\n",
    "        results_file = os.path.join(results_folder, f\"{tree_file.split('.')[0]}.{tree_file.split('.')[1]}_phylo_cv_results.csv\")\n",
    "        with open(results_file, \"w\") as f:\n",
    "            f.write(\"Tree,Relation_Handling,N_Folds,Model,Threshold,R2,MAE,MAPE,MSE,RMSE\\n\") # Header\n",
    "\n",
    "        for relation_method in relation_handling_methods:\n",
    "            for n_folds in n_folds_range:\n",
    "                for percentile in percentile_threshold_range:\n",
    "                    percentile_dist_threshold = percentile_threshold(dist_matrix, percentile=percentile)\n",
    "                    tip_to_fold = phylo_weighted_cv(distance_matrix=dist_matrix, tip_names=tip_names, n_folds=n_folds, distance_threshold=percentile_dist_threshold, relation_mode=relation_method)\n",
    "                    tr_temp = tr.copy()\n",
    "                    tr_temp = tr_temp.reindex(tip_to_fold.index)\n",
    "                    tr_temp['Fold'] = tip_to_fold['Fold']\n",
    "                    if relation_method == 'leave_out':\n",
    "                        tr_temp = tr_temp[tr_temp['Fold'] != -1]\n",
    "                    tr_phylo_folds = tr_temp['Fold'].tolist()\n",
    "                    tr_temp.drop('Fold', axis=1, inplace=True)\n",
    "                    y = tr_temp.loc[:, mt].values\n",
    "                    tr_temp.drop(mt, axis=1, inplace=True)\n",
    "                    \n",
    "                    if tr_temp.shape[0] > 100:\n",
    "                        # Run deepBreaks pipeline (assuming necessary functions exist)\n",
    "                        report, top = model_compare_cv(X=tr_temp, y=y, preprocess_pipe=prep_pipeline,\n",
    "                                                    models_dict=get_models(ana_type=ana_type, dataset=ds, encoding=encoding),\n",
    "                                                    scoring=get_scores(ana_type=ana_type),\n",
    "                                                    report_dir=report_dir,\n",
    "                                                    cv=10, ana_type=ana_type, cache_dir=report_dir)\n",
    "                        # Record R^2 values for each model\n",
    "                        with open(results_file, \"a\") as f:\n",
    "                            for model_name, r2_value, mae_value, mape_value, mse_value, rmse_value in zip(report.index.to_list(), report[\"R2\"],report[\"MAE\"],report[\"MAPE\"],report[\"MSE\"],report[\"RMSE\"]):\n",
    "                                f.write(f\"{tree_file},{relation_method},{n_folds},{model_name},{percentile},{r2_value},{mae_value},{mape_value},{mse_value},{rmse_value}\\n\")\n",
    "                        #removing the default model report file between iterations\n",
    "                        os.remove(f'{report_dir}/model_report.csv')\n",
    "                        shutil.rmtree(f'{report_dir}/joblib')\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "    # The next three functions are for generating several graphs for various analyses on relationship between handling methods and model metrics. \n",
    "    plot_phylo_cv_line_graphs(results_folder, results_file, atts_of_intrst=['R2', 'MAE', 'MAPE', 'MSE', 'RMSE'])\n",
    "    \n",
    "    plot_phylo_cv_bar_graphs(results_folder, results_file, atts_of_intrst=['R2', 'MAE', 'MAPE', 'MSE', 'RMSE'])\n",
    "    \n",
    "    plot_phylo_cv_indv_model_graphs(results_folder, results_file)\n",
    "    \n",
    "    # Moving the folder with alignment to the results folder to have as a sort of metadata for post analysis \n",
    "    shutil.move(report_dir, results_folder)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
