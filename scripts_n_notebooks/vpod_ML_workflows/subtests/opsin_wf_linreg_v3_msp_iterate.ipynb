{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f4de42",
   "metadata": {},
   "source": [
    "# <font color=green>deepBreaks Applications</font>\n",
    "## Modeling spectral tuning sites of opsin proteins based on amino-acid sequence...  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5b43e3c",
   "metadata": {},
   "source": [
    "# <font color=red>Step 0: mySQL DB Setup -</font> Script 0\n",
    "## *The following script sets up the schema for our vizphiz database.*\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "import mysql\n",
    "import mysql.connector\n",
    "#install mysql-connector-python // NOT mysql-connector\n",
    "import re\n",
    "import os\n",
    "import datetime \n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password= \"Geass5566!!\")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try:\n",
    "  mycursor.execute(\"\"\"\n",
    "  DROP DATABASE vizphiz_db;\n",
    "  \"\"\")\n",
    "  mydb.commit() \n",
    "except:\n",
    "  \"vizphiz_db does not yet exist!\"\n",
    "  pass\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE DATABASE vizphiz_db;\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "USE vizphiz_db;\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE lamdamax\n",
    "(\n",
    "id int unsigned not null primary key,\n",
    "genus varchar(50),\n",
    "species varchar(50),\n",
    "celltype varchar(50),\n",
    "cellsubtype varchar(50),\n",
    "lamdamax decimal(9,5),\n",
    "error decimal(9,5),\n",
    "chromophore varchar(50),\n",
    "method varchar(50),\n",
    "stage varchar(50),\n",
    "refid int,\n",
    "notes varchar(1000)\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE heterologous\n",
    "(\n",
    "hetid int unsigned not null primary key,\n",
    "genus varchar(50),\n",
    "species varchar(50),\n",
    "accession varchar(500),\n",
    "mutations varchar(500),\n",
    "lamdamax decimal(9,5),\n",
    "error decimal(9,5),\n",
    "cellculture varchar(50),\n",
    "purification varchar(50),\n",
    "spectrum varchar(50),\n",
    "sourcetype varchar(50),\n",
    "refid int,\n",
    "notes varchar(1000)\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE links\n",
    "(\n",
    "linkid int unsigned not null primary key,\n",
    "accession varchar(500),\n",
    "maxid int,\n",
    "refid int,\n",
    "evidence varchar(1000)\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE search\n",
    "(\n",
    "searchid int unsigned not null primary key,\n",
    "researcher varchar(50),\n",
    "month int,\n",
    "year int,\n",
    "engine varchar(500),\n",
    "keywords varchar(500)\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit() \n",
    "\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE opsins\n",
    "(\n",
    "opsinid int unsigned not null primary key,\n",
    "genefamily varchar(50),\n",
    "genenames varchar(50),\n",
    "genus varchar(50),\n",
    "phylum varchar(25),\n",
    "species varchar(50),\n",
    "db varchar(50),\n",
    "accession varchar(500),\n",
    "dna varchar(10000),\n",
    "aa varchar(3333),\n",
    "refid int\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "mydb.commit()\n",
    "\n",
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE refs\n",
    "(\n",
    "refid int,\n",
    "doilink varchar(100),\n",
    "searchid int\n",
    ");\n",
    "\"\"\")\n",
    "mydb.commit()\n",
    "\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "import mysql\n",
    "import mysql.connector\n",
    "#install mysql-connector-python // NOT mysql-connector\n",
    "import re\n",
    "import os\n",
    "import datetime \n",
    "import subprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5778bef",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 1 - Import heterologous.tsv into mySQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\"\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "file1 = open('heterologous.tsv', 'r', encoding=\"utf8\")\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    columns = line.split(\"\\t\")\n",
    "    print(columns)\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO vizphiz_db.heterologous (hetid, genus, species, accession, mutations, lamdamax, error, cellculture, purification, spectrum, sourcetype, refid) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    val = (columns[0], columns[1], columns[2], columns[3], columns[4], columns[5], columns[6], columns[7], columns[8], columns[9], columns[10], columns[11])\n",
    "    print(sql)\n",
    "    print(val)\n",
    "\n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    mydb.commit()\n",
    "\n",
    "    print(mycursor.rowcount, \"record inserted.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31e8500e",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 2 - Import opsindb.tsv into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\"\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "file1 = open('opsindb.tsv', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    columns = line.split(\"\\t\")\n",
    "\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO vizphiz_db.opsins (opsinid, genefamily, genenames, phylum, genus, species, db, accession, dna, aa, refid) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    val = (columns[0], columns[1], columns[2], columns[3], columns[4], columns[5], columns[6], columns[7], columns[8], columns[9], columns[10])\n",
    "    print(sql)\n",
    "    print(val)\n",
    "\n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    mydb.commit()\n",
    "\n",
    "    print(mycursor.rowcount, \"record inserted.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6c27589",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 1: Extract Data From Vizphiz</font>\n",
    "### Output = 5 different 'versions' // 'splits' of the data. \n",
    "### !Take outputs and run through MAFFT before moving on to STEP2!\n",
    "### Suggested parameters for 'mafft' alignment are...\n",
    "1. Fasta Format (Sorted)\n",
    "\n",
    "2. Strategy = FFT-NS-2 // G-INS-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "import mysql\n",
    "import mysql.connector\n",
    "#install mysql-connector-python // NOT mysql-connector\n",
    "import re\n",
    "import os\n",
    "import datetime \n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rod = re.compile('Rh[0-2]|exoRh')\n",
    "d = re.compile('^NM_001014890.2$|^NM_001014890$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory preperation\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seq_report_dir = str(f'vizphiz_data_splits_{dt_label}')\n",
    "os.makedirs(seq_report_dir)\n",
    "\n",
    "wd_output = f'{seq_report_dir}/wds.txt'\n",
    "sws_output = f'{seq_report_dir}/swd.txt'\n",
    "mws_output = f'{seq_report_dir}/mwd.txt'\n",
    "rod_output = f'{seq_report_dir}/rod.txt'\n",
    "wd_ni_output = f'{seq_report_dir}/wds_ni.txt'\n",
    "inv_output = f'{seq_report_dir}/inv_only.txt'\n",
    "nmoc_output = f'{seq_report_dir}/nmoc.txt'\n",
    "mut_output = f'{seq_report_dir}/mut_only.txt'\n",
    "wh_metadata = f'{seq_report_dir}/wds_meta.tsv'\n",
    "sw_metadata = f'{seq_report_dir}/sws_meta.tsv'\n",
    "mw_metadata = f'{seq_report_dir}/mws_meta.tsv'\n",
    "rh_metadata = f'{seq_report_dir}/rod_meta.tsv'\n",
    "wd_ni_metadata = f'{seq_report_dir}/wds_ni_meta.tsv'\n",
    "inv_metadata = f'{seq_report_dir}/inv_meta.tsv'\n",
    "nmoc_metadata = f'{seq_report_dir}/nmoc_meta.tsv'\n",
    "mut_metadata = f'{seq_report_dir}/mut_meta.tsv'\n",
    "\n",
    "meta_data_list = [wh_metadata,sw_metadata,mw_metadata,rh_metadata,wd_ni_metadata,inv_metadata,nmoc_metadata,mut_metadata]\n",
    "\n",
    "m = 0\n",
    "s = 0\n",
    "l = 0\n",
    "r = 0\n",
    "c = 0\n",
    "z = 0\n",
    "q = 0\n",
    "mut = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database=\"vizphiz\",\n",
    "  password=\"Geass5566!!\"\n",
    ") \n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "sql = \"select DISTINCT o.genus,o.species,o.genefamily,o.accession,h.lamdamax,o.aa,o.phylum,h.mutations from vizphiz_db.opsins o, vizphiz_db.heterologous h WHERE (o.accession = h.accession AND o.refid = h.refid); \"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "\n",
    "for x in myresult:  \n",
    "\n",
    "  if (x[4] == 0):\n",
    "    pass   \n",
    "  else:  \n",
    "  #REG-DATA SECTION    \n",
    "    with open(wd_output, 'a') as f:\n",
    "      if m == 0:\n",
    "        f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "      if (d.match(x[3])):\n",
    "        pass\n",
    "      else:\n",
    "        m += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(m)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    with open(wd_ni_output, 'a') as f:\n",
    "      if x[6] != \"Chordata\" or d.match(x[3]):\n",
    "        pass\n",
    "      else:\n",
    "        if c == 0:\n",
    "          f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "        c += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(c)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    with open(inv_output, 'a') as f:\n",
    "      if (x[6] != \"Chordata\"):\n",
    "        if q == 0:\n",
    "          f.write(\">Squid\\nMGRDLRDNETWWYNPSIVVHPHWREFDQVPDAVYYSLGIFIGICGIIGCGGNGIVIYLFTKTKSLQTPANMFIINLAFSDFTFSLVNGFPLMTISCFLKKWIFGFAACKVYGFIGGIFGFMSIMTMAMISIDRYNVIGRPMAASKKMSHRRAFIMIIFVWLWSVLWAIGPIFGWGAYTLEGVLCNCSFDYISRDSTTRSNILCMFILGFFGPILIIFFCYFNIVMSVSNHEKEMAAMAKRLNAKELRKAQAGANAEMRLAKISIVIVSQFLLSWSPYAVVALLAQFGPLEWVTPYAAQLPVMFAKASAIHNPMIYSVSHPKFREAISQTFPWVLTCCQFDDKETEDDKDAETEIPAGESSDAAPSADAAQMKEMMAMMQKMQQQQAAYPPQGYAPPPQGYPPQGYPPQGYPPQGYPPQGYPPPPQGAPPQGAPPAAPPQGVDNQAYQA\\n\")\n",
    "        q += 1 \n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(q)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "      else:\n",
    "        pass\n",
    "\n",
    "    with open(nmoc_output, 'a') as f:\n",
    "      p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if p.search(x[3]) or \"-\" in x[3]:\n",
    "        pass\n",
    "      else:\n",
    "        if z == 0:\n",
    "          f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:\n",
    "          z += 1 \n",
    "          #This makes the fasta format file\n",
    "          seq = \">S\" + str(z)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "\n",
    "    with open(mut_output, 'a') as f:\n",
    "      p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if p.search(x[3]) or \"-\" in x[3]:\n",
    "        if mut == 0:\n",
    "          f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:\n",
    "          mut += 1 \n",
    "          #This makes the fasta format file\n",
    "          seq = \">M\" + str(mut)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "      else:\n",
    "        pass\n",
    "\n",
    "    with open(sws_output, 'a') as f:\n",
    "      p = re.compile('^SWS|^UVS')\n",
    "      if p.match(x[2]):\n",
    "        s+=1\n",
    "        if s == 1:\n",
    "          f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")  \n",
    "      #This makes the fasta format file\n",
    "        seq = \">S\" + str(s)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    with open(mws_output, 'a') as f:\n",
    "      p = re.compile('^MWS|^LWS')\n",
    "      if p.match(x[2]):\n",
    "        l+=1\n",
    "        if l == 1:\n",
    "          f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "        #This makes the fasta format file\n",
    "        seq = \">S\" + str(l)\n",
    "        f.write(seq)\n",
    "        seq2 = str('\\n' + x[5] + '\\n')\n",
    "        f.write(seq2)\n",
    "\n",
    "    with open(rod_output, 'a') as f:\n",
    "      p = re.compile('Rh[0-2]|exoRh')\n",
    "      if p.match(x[2]):\n",
    "        if r == 0:\n",
    "          f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "        if (x[6] != \"Chordata\") or d.match(x[3]):\n",
    "          pass\n",
    "        else:\n",
    "          r+=1\n",
    "          #This makes the fasta format file\n",
    "          seq = \">S\" + str(r)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "\n",
    "  #METADATA SECTION\n",
    "    with open(wh_metadata, 'a') as g:\n",
    "      if m == 1:\n",
    "        g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")  \n",
    "        g.write(\"Bovine\\t500.0000\\tBos_tarus\\tRh1\\tNM_001014890\\n\")\n",
    "      if (d.match(x[3])):\n",
    "        pass\n",
    "      else:        \n",
    "        md =  str(\"S\" + str(m) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(wd_ni_metadata, 'a') as g:\n",
    "      p = re.compile('^Rtc|^BRh[0-3]|Pr[A-Z]|Rh1,Rh3|^IV|^inv')\n",
    "      if x[6] != \"Chordata\" or d.match(x[3]):\n",
    "        pass\n",
    "      else:\n",
    "        if c == 1:\n",
    "          g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "          g.write(\"Bovine\\t500.0000\\tBos_tarus\\tRh1\\tNM_001014890\\n\")\n",
    "\n",
    "        md =  str(\"S\" + str(c) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(inv_metadata, 'a') as g:\n",
    "      if (x[6] != \"Chordata\"):\n",
    "        if q == 1:\n",
    "          g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "          g.write(\"Squid\\t473.0000\\tTodarodes_pacificus\\tRh1\\tX70498\\n\")\n",
    "\n",
    "        md =  str(\"S\" + str(q) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "      else:\n",
    "        pass\n",
    "          \n",
    "    with open(sw_metadata, 'a') as g:\n",
    "    #This makes the metadata formatted for a linear regression model.\n",
    "      p = re.compile('^SWS|^UVS')\n",
    "      if p.match(x[2]):\n",
    "        if s == 1:\n",
    "          g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "          g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")  \n",
    "        md =  str(\"S\" + str(s) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(mw_metadata, 'a') as g:\n",
    "      #This makes the metadata formatted for a linear regression model.\n",
    "      p = re.compile('^MWS|^LWS')\n",
    "      if p.match(x[2]):\n",
    "        if l == 1:\n",
    "          g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")  \n",
    "          g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")  \n",
    "        md =  str(\"S\" + str(l) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "        g.write(md)\n",
    "\n",
    "    with open(rh_metadata, 'a') as g:\n",
    "      #This makes the metadata formatted for a linear regression model.\n",
    "      p = re.compile('Rh[0-3]|exoRh')\n",
    "\n",
    "      if p.match(x[2]):\n",
    "        if r == 1:\n",
    "          g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "          g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")\n",
    "        if (x[6] != \"Chordata\") or d.match(x[3]):\n",
    "          pass\n",
    "        else:  \n",
    "          md =  str(\"S\" + str(r) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "\n",
    "    with open(nmoc_metadata, 'a') as g:\n",
    "      p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if (p.search(x[3]) or \"-\" in x[3] or \"_(\" in x[3]):\n",
    "        pass\n",
    "      else:\n",
    "        if z == 1:\n",
    "          g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")  \n",
    "          g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:        \n",
    "          md =  str(\"S\" + str(z) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "\n",
    "    with open(mut_metadata, 'a') as g:\n",
    "      p = re.compile('_[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "      if (p.search(x[3]) or \"-\" in x[3]):\n",
    "        if mut == 1:\n",
    "          g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")  \n",
    "          g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")\n",
    "        if(d.match(x[3])):\n",
    "          pass\n",
    "        else:        \n",
    "          md =  str(\"M\" + str(mut) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "      else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1dd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msp_erg_raw = open('./msp_test_data/msp_erg_raw.txt').readlines()\n",
    "for lines in msp_erg_raw:\n",
    "  with open(wd_output, 'a') as f:\n",
    "    f.write(lines)\n",
    "  with open(wd_ni_output, 'a') as f:\n",
    "    f.write(lines)\n",
    "  with open(rod_output, 'a') as f:\n",
    "    f.write(lines)\n",
    "  with open(nmoc_output, 'a') as f:\n",
    "    f.write(lines)\n",
    "  with open(inv_output, 'a') as f:\n",
    "    f.write(lines)\n",
    "  with open(mws_output, 'a') as f:\n",
    "    f.write(lines)\n",
    "  with open(sws_output, 'a') as f:\n",
    "    f.write(lines)\n",
    "  with open(mut_output, 'a') as f:\n",
    "    f.write(lines)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "261d0aca",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 2: Align Raw Data and Format for 'deepBreaks'</font>\n",
    "## REMINDER - You will need to change the directory for the 'mafft_exe' variable to the one of your own operating system!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import MafftCommandline\n",
    "from Bio import AlignIO\n",
    "\n",
    "data_split_list = [wd_output,sws_output,mws_output,rod_output,wd_ni_output,inv_output,nmoc_output,mut_output]\n",
    "output_list = []\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat' \n",
    "\n",
    "for data in data_split_list:\n",
    "    output = f'{data.split(\".\")[0]}_aligned.txt'\n",
    "    mafft_cline = MafftCommandline(mafft_exe, input= f'./{data}')\n",
    "    print(mafft_cline)\n",
    "\n",
    "    stdout, stderr = mafft_cline()\n",
    "\n",
    "    with open(output, \"w\") as handle:\n",
    "        handle.write(stdout)\n",
    "    align = AlignIO.read(output, \"fasta\")\n",
    "    output_list.append(f'{output}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81289b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_list)\n",
    "\n",
    "for item in output_list:\n",
    "    output = item.split('.')[0]\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e914c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter list of aligned text files here.\n",
    "inputs = output_list\n",
    "deep_breaks_input_data = []\n",
    "# inputs = ['wds_aligned.txt','wds_ni_aligned.txt','rod_aligned.txt','nmoc_aligned.txt']\n",
    "##enter list of names for desired formatted fasta files here.\n",
    "# output = ['wds_fmt.fasta','wds_ni_fmt.fasta','rod_fmt.fasta','nmoc_fmt.fasta']\n",
    "i=0\n",
    "k = 0\n",
    "for item in inputs:\n",
    "    print(item)\n",
    "    lines = open(inputs[i]).readlines()\n",
    "    output = f'./{inputs[i].split(\".\")[0]}_db_fmt.fasta'\n",
    "    deep_breaks_input_data.append(output)\n",
    "    print(output)\n",
    "    file = open(output, 'w')\n",
    "    m=0\n",
    "    for line in lines:\n",
    "        snip = str(lines[k])\n",
    "        if '>' in snip:\n",
    "            if m == 0:\n",
    "                m+=1\n",
    "            else:\n",
    "                file.write(\"\\n\")\n",
    "            file.write(snip)\n",
    "        else:\n",
    "            entry = \"\"\n",
    "            entry = str(snip.replace(\"\\n\",\"\"))\n",
    "            file.write(entry)\n",
    "        k+=1\n",
    "    k = 0\n",
    "    i+=1\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deep_breaks_input_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2969791",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 3: deepBreaks</font>\n",
    "## THIS IS A LONG SECTION! \n",
    "### STEP 4 doesn't start until Cell 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eed2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils import get_models, get_scores, get_params, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from deepBreaks.models import model_compare_cv, finalize_top, importance_from_pipe, mean_importance, summarize_results\n",
    "from deepBreaks.visualization import plot_scatter, dp_plot, plot_imp_model, plot_imp_all\n",
    "from deepBreaks.preprocessing import write_fasta\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a689c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsin_data_count = 0\n",
    "ref_ali_list = []\n",
    "ref_meta_list = []\n",
    "ref_mod_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for opsindata in deep_breaks_input_data:\n",
    "    # defining user params, file pathes, analysis type\n",
    "\n",
    "    # path to sequences\n",
    "    seqFileName = opsindata\n",
    "\n",
    "    # path to metadata\n",
    "    metaDataFileName = meta_data_list[opsin_data_count] \n",
    "\n",
    "    # name of the phenotype\n",
    "    mt = 'Lambda_Max'\n",
    "\n",
    "    # type of the sequences\n",
    "    seq_type = 'aa'\n",
    "\n",
    "    # type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "    ana_type = 'reg' \n",
    "\n",
    "    gap_threshold = 0.6\n",
    "\n",
    "    # making a unique directory for saving the reports of the analysis\n",
    "    print('direcory preparation')\n",
    "    dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    seqFile = seqFileName.split('/')[2]\n",
    "    print(seqFile)\n",
    "    seqFile = seqFile.split('.')[0]\n",
    "    print(seqFile)\n",
    "    report_dir = str(seqFile +'_' + mt + '_' + dt_label)\n",
    "    os.makedirs(report_dir)\n",
    "\n",
    "\n",
    "    print('reading meta-data')\n",
    "    # importing metadata\n",
    "    meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "    metaFile = metaDataFileName.split('/')[1]\n",
    "    # importing sequences data\n",
    "    print('reading fasta file')\n",
    "    tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=gap_threshold)\n",
    "\n",
    "    #creating a copy of the input fasta file and metadata file into the report directory\n",
    "    shutil.copy2(f'{seqFileName}' , report_dir)\n",
    "    shutil.copy2(f'{metaDataFileName}' , report_dir)\n",
    "    ref_meta_list.append(f'./{report_dir}/{metaFile}')\n",
    "    #creating a copy of inout fasta file minus any of the sequences with no match in metadata file\n",
    "    #this file will be used for aligning new test sequences by the user - using the mafft 'add sequence' function\n",
    "    tr_for_ref = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=1.0)\n",
    "    tr_for_ref = tr_for_ref.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "    tr_for_ref.drop(mt, axis=1, inplace=True)\n",
    "    fasta_file_name = f'{seqFile}_for_seq_insertion.fasta'\n",
    "    write_fasta(dat = tr_for_ref, fasta_file = fasta_file_name , report_dir = report_dir)\n",
    "    ref_ali_list.append(f'./{report_dir}/{fasta_file_name}')\n",
    "    #converting the pandas df which contains all sequences after the gap_threshold has cleaned all the excess gaps\n",
    "    write_fasta(dat = tr, fasta_file = f'{seqFile}_gap_dropped.fasta' , report_dir = report_dir)\n",
    "\n",
    "    #making a copy of tr dataframe to isolate our msp invertebrate test sequences\n",
    "    msp = tr.copy()\n",
    "    #merging in lambda max values, simultaneously dropping all sequences without entries in metadata file\n",
    "    tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "    #tr.shape\n",
    "    #taking the numer of sequences in the training dataset after the sequences with no entry in the metadata file (aka our msp sequences)\n",
    "    sv_msp = tr.shape[0]\n",
    "    #dropping all other sequences from our msp dataframe except the msp invertebrate sequences.\n",
    "    msp = msp.iloc[sv_msp:].copy()\n",
    "    #msp.shape\n",
    "    y = tr.loc[:, mt].values\n",
    "    tr.drop(mt, axis=1, inplace=True)\n",
    "    print('Shape of data is: ', tr.shape)\n",
    "    #copying the referece sequence into a dataframe later and saving a copy in the report directory \n",
    "    try:\n",
    "        reference_seq = tr.loc['Bovine'].copy()\n",
    "        ref_seq_name = 'bovine'\n",
    "        #print(bovine)\n",
    "    except:\n",
    "        reference_seq = tr.loc['Squid'].copy()\n",
    "        ref_seq_name = 'squid'\n",
    "        #print(squid)\n",
    "    reference_seq.to_csv(path_or_buf= f'{report_dir}/ref_sequence.csv',index = True,mode=\"w\")\n",
    "\n",
    "    #settingthe paramaters for our ML pipeline\n",
    "    prep_pipeline = make_pipeline(\n",
    "        steps=[\n",
    "            ('mc', MisCare(missing_threshold=0.05)),\n",
    "            ('cc', ConstantCare()),\n",
    "            ('ur', URareCare(threshold=0.025)),\n",
    "            ('cc2', ConstantCare()),\n",
    "            ('one_hot', CustomOneHotEncoder()),\n",
    "            ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=False)),\n",
    "            ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.05, keep=False))\n",
    "        ])\n",
    "\n",
    "    #training models\n",
    "    report, top = model_compare_cv(X=tr, y=y, preprocess_pipe=prep_pipeline,\n",
    "                                models_dict=get_models(ana_type=ana_type),\n",
    "                                scoring=get_scores(ana_type=ana_type),\n",
    "                                report_dir=report_dir,\n",
    "                                cv=12, ana_type=ana_type, cache_dir=report_dir)\n",
    "\n",
    "                                \n",
    "    time.sleep(1)\n",
    "    #setting parameters for tuning the top 3 performing models\n",
    "    prep_pipeline = make_pipeline(\n",
    "        steps=[\n",
    "            ('mc', MisCare(missing_threshold=0.05)),\n",
    "            ('cc', ConstantCare()),\n",
    "            ('ur', URareCare(threshold=0.025)),\n",
    "            ('cc2', ConstantCare()),\n",
    "            ('one_hot', CustomOneHotEncoder()),\n",
    "            ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=True)),\n",
    "            ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.05, keep=True))\n",
    "        ])\n",
    "\n",
    "    modified_top = []\n",
    "    mtml = []\n",
    "    for model in top:\n",
    "        modified_top.append(make_pipeline(steps=[('prep', prep_pipeline), model.steps[-1]]))\n",
    "        my_top_models = str(model[1:])\n",
    "        #print(my_top_models)\n",
    "        my_top_models = my_top_models.split(\"'\")[3]\n",
    "        mtml.append(my_top_models)\n",
    "        #print(my_top_models)\n",
    "\n",
    "    #print(mtml)\n",
    "    time.sleep(1)\n",
    "\n",
    "    #tuning the top 3 performing models \n",
    "    top = finalize_top(X=tr, y=y, top_models=modified_top, grid_param=get_params(),report_dir=report_dir, cv=10)\n",
    "    #summarize the results by extracting feature importance and p-values and grouping correlated features.\n",
    "    sr = summarize_results(top_models=top, report_dir=report_dir)\n",
    "    #plot a scatter plot with -log of (p-value) column as the x-axis and the values of the other columns \n",
    "    scatter_plot = plot_scatter(summary_result=sr, report_dir=report_dir)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    #plot mean relative importance of each feature - corresponding to an amino acid position.\n",
    "    mean_imp = mean_importance(top, report_dir=report_dir)\n",
    "\n",
    "    dp_plot(importance=mean_imp,imp_col='mean', model_name='mean', report_dir=report_dir)\n",
    "    tr = prep_pipeline[:4].fit_transform(tr)\n",
    "\n",
    "    for model in top:\n",
    "        model_name = model.steps[-1][0]\n",
    "        dp_plot(importance=importance_from_pipe(model),\n",
    "                imp_col='standard_value',\n",
    "                model_name = model_name, report_dir=report_dir)\n",
    "        \n",
    "        plot_imp_model(importance=importance_from_pipe(model), \n",
    "                X_train=tr, y_train=y, model_name=model_name,\n",
    "                    meta_var='meta', model_type=ana_type, report_dir=report_dir)\n",
    "\n",
    "    time.sleep(1)\n",
    "                    \n",
    "    pl = plot_imp_all(final_models=top,\n",
    "                    X_train=tr, y_train=y,\n",
    "                    model_type = ana_type,\n",
    "                    report_dir=report_dir, max_plots=10,\n",
    "                    figsize=(2.5, 3))\n",
    "\n",
    "    from deepBreaks.utils import load_obj\n",
    "    import joblib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.colors as mcolors\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import mean_absolute_percentage_error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    #load and test the top performing linear regression model.\n",
    "    top_per_mod = report_dir + '/' + mtml[0] + '.pkl'\n",
    "    ref_mod_list.append(f'./{top_per_mod}')\n",
    "    load_rf = load_obj(top_per_mod)\n",
    "    time.sleep(3)\n",
    "\n",
    "    #running prediction on msp invertebrate data\n",
    "    msp_predictions = load_rf.predict(msp)\n",
    "    #print(msp_predictions)\n",
    "    meta = \"./msp_test_data/erg_msp_meta.tsv\"\n",
    "    msp_meta = pd.read_csv(meta, sep=\"\\t\", index_col = False)\n",
    "    #msp_meta.head()\n",
    "\n",
    "    #making msp df for analyzing test results, just as we did for the 'base_test' df - then saving results to csv file\n",
    "    lmax_msp = (msp_meta['Lambda_Max'])\n",
    "    lm = []\n",
    "    for i in lmax_msp:\n",
    "        lm.append(float(i))\n",
    "    columns = ['Species','Accession','Lambda_Max','Predicted','Differnce']\n",
    "    msp_test = pd.DataFrame(index=msp.index, columns = columns)\n",
    "    msp_test['Predicted'] = msp_predictions\n",
    "    msp_test['Species'][0:31] = msp_meta['Species']\n",
    "    msp_test['Accession'][0:31] = msp_meta['Accession']\n",
    "    #msp_test.head()\n",
    "    msp_test['Lambda_Max'][0:31] = lm\n",
    "    msp_test['Differnce'] = msp_test['Predicted'] - msp_test['Lambda_Max']\n",
    "    #msp_test.head()\n",
    "    msp_test.to_csv(path_or_buf= f'{report_dir}/msp_test_results.csv',index = 'Feature',mode=\"w\")\n",
    "\n",
    "    #calculating r^2, mae, mape, sqe, and rsque for the model on our invertebrate msp data - saved to same file as base test.\n",
    "    msp_rsq = load_rf.score(msp[0:31], msp_test['Lambda_Max'][0:31])\n",
    "    #print(msp_rsq)\n",
    "    msp_mae = mean_absolute_error(msp_test['Predicted'][0:31], msp_test['Lambda_Max'][0:31])\n",
    "    #print(msp_mae)\n",
    "    msp_mape = mean_absolute_percentage_error(msp_test['Predicted'][0:31], msp_test['Lambda_Max'][0:31])\n",
    "    #print(msp_mape)\n",
    "    msp_sqe = mean_squared_error(msp_test['Predicted'][0:31], msp_test['Lambda_Max'][0:31])\n",
    "    #print(msp_sqe)\n",
    "    msp_rsqe = mean_squared_error(msp_test['Predicted'][0:31], msp_test['Lambda_Max'][0:31], squared = False)\n",
    "    #print(msp_rsqe)\n",
    "\n",
    "    \n",
    "    model_testing_report = f'{report_dir}/model_testing report.tsv'\n",
    "    with open(model_testing_report , 'w') as f:\n",
    "        f.write(f'\\nMSP Model Test R^2\\tMAE\\tMAPE\\tSQE\\tRSQE\\n')\n",
    "        f.write(f'{str(msp_rsq)}\\t{str(msp_mae)}\\t{str(msp_mape)}\\t{str(msp_sqe)}\\t{str(msp_rsqe)}')\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    #plotting the predicted vs. known lambda max for the invertebrate msp data\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.50, 4.00]\n",
    "    plt.title(\"$λ_{max}$ Predictions for Invertebrate MSP Data\")\n",
    "    plt.scatter(msp_test['Lambda_Max'][0:31], msp_predictions[0:31], c=msp_predictions[0:31], ec = 'k', edgecolors='k', s = 35)\n",
    "    plt.plot(msp_test['Lambda_Max'][0:31], msp_test['Lambda_Max'][0:31], c = 'k', linewidth = '1.0', ls = '--', dashes = (1,3))\n",
    "    plt.xlabel('Known $λ_{max}$ (nm)')\n",
    "    plt.ylabel('Predicted $λ_{max}$ (nm)')\n",
    "    plt.annotate(f\"$R^2$ = {load_rf.score(msp[0:31], msp_test['Lambda_Max'][0:31]):.3f}\",(325, 535), fontsize = 20, c = 'k')\n",
    "    time.sleep(1)\n",
    "    fileout = f'{report_dir}/msp_dp.pdf'\n",
    "    plt.savefig(fileout)\n",
    "    plt.show()\n",
    "\n",
    "    #translate candidate STSs to the bovine or squid equivalent \n",
    "    #bovine and squid sequence dataframes were saved earlier and are called again here\n",
    "    m = 0\n",
    "    tm = ''\n",
    "    k=0\n",
    "    gaps=0\n",
    "    #import importance_report.csv from report_dir\n",
    "    true_pos = []\n",
    "    aa = []\n",
    "    tmd = []\n",
    "    df = pd.read_csv(f'{report_dir}\\importance_report.csv')\n",
    "    #take the list of important sites and translate them to the bovine standard equivalent, \n",
    "    #we do this by taking the site number and subtracting the number of '-' between the start of the sequence and the desired site. \n",
    "    for rows in reference_seq.values:  \n",
    "        rows = str(rows)\n",
    "        #print(rows)\n",
    "        if rows == 'nan':\n",
    "        #We want to write the 'true_pos', 'aa', and 'TMD' to the 'importance_report' csv file\n",
    "            gaps += 1\n",
    "            k += 1\n",
    "            true_pos.append('NA')\n",
    "            aa.append('-')\n",
    "            tmd.append('NA')\n",
    "        else:\n",
    "            #print(\"The number of gaps is \" + str(gaps))\n",
    "            k+=1\n",
    "            trans_site = k - gaps\n",
    "            if ref_seq_name == 'bovine':\n",
    "                if trans_site in range(3,37):\n",
    "                    tm = 'N-Termina'\n",
    "                elif trans_site in range(37,62):\n",
    "                    tm = '1'\n",
    "                elif trans_site in range(74,96):\n",
    "                    tm = '2'\n",
    "                elif trans_site in range(111,133):\n",
    "                    tm = '3'\n",
    "                elif trans_site in range(153,174):\n",
    "                    tm = '4'\n",
    "                elif trans_site in range(203,225):\n",
    "                    tm = '5'\n",
    "                elif trans_site in range(253,275):\n",
    "                    tm = '6'\n",
    "                elif trans_site in range(287,309):\n",
    "                    tm = '7'\n",
    "                else:\n",
    "                    tm = 'CT/EC'\n",
    "            else:\n",
    "                if trans_site in range(3,34):\n",
    "                    tm = 'N-Termina'\n",
    "                elif trans_site in range(34,59):\n",
    "                    tm = '1'\n",
    "                elif trans_site in range(71,97):\n",
    "                    tm = '2'\n",
    "                elif trans_site in range(110,132):\n",
    "                    tm = '3'\n",
    "                elif trans_site in range(152,173):\n",
    "                    tm = '4'\n",
    "                elif trans_site in range(200,225):\n",
    "                    tm = '5'\n",
    "                elif trans_site in range(262,284):\n",
    "                    tm = '6'\n",
    "                elif trans_site in range(294,315):\n",
    "                    tm = '7'\n",
    "                else:\n",
    "                    tm = 'CT/EC'                \n",
    "            \n",
    "            true_pos.append(str(trans_site))\n",
    "            aa.append(rows)\n",
    "            tmd.append(tm)\n",
    "    true_pos.pop()\n",
    "    aa.pop()\n",
    "    tmd.pop()\n",
    "\n",
    "    df['true_position'] = true_pos\n",
    "    df['TMD'] = tmd\n",
    "    df['amino_acid'] = aa\n",
    "    df.to_csv(path_or_buf= os.path.join(report_dir,r'importance_report.csv'),index = 'Feature',mode=\"w\")\n",
    "    #df.head()\n",
    "\n",
    "    #cycling to next set of data split files.\n",
    "    opsin_data_count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9245439",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./{seq_report_dir}/path_to_ref_files.txt', 'w') as f:\n",
    "    f.write('Here is a list of the paths to all aligned reference sequence files for inserting new sequences into an existing alignment before running a model prediction...\\n')\n",
    "    f.write(str(ref_ali_list) + '\\n')\n",
    "    f.write('Here is the list of paths for the corresponding metadata files...\\n')\n",
    "    f.write(str(ref_meta_list) + '\\n')\n",
    "    f.write('Finally, here is list of the paths to all the top performing models from each of the data splits...\\n')\n",
    "    f.write(str(ref_mod_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79399f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref_ali_list = ['./wds_aligned_db_fmt_Lambda_Max_2023-08-08_15-08-05/wds_aligned_db_fmt.fasta', './swd_aligned_db_fmt_Lambda_Max_2023-08-08_15-10-55/swd_aligned_db_fmt_for_seq_insertion.fasta', './mwd_aligned_db_fmt_Lambda_Max_2023-08-08_15-13-55/mwd_aligned_db_fmt_for_seq_insertion.fasta', './rod_aligned_db_fmt_Lambda_Max_2023-08-08_15-15-29/rod_aligned_db_fmt_for_seq_insertion.fasta', './wds_ni_aligned_db_fmt_Lambda_Max_2023-08-08_15-18-19/wds_ni_aligned_db_fmt_for_seq_insertion.fasta', './inv_only_aligned_db_fmt_Lambda_Max_2023-08-08_15-23-06/inv_only_aligned_db_fmt_for_seq_insertion.fasta', './nmoc_aligned_db_fmt_Lambda_Max_2023-08-08_15-24-51/nmoc_aligned_db_fmt_for_seq_insertion.fasta']\n",
    "\n",
    "#ref_meta_list = ['./wds_aligned_db_fmt_Lambda_Max_2023-08-08_15-08-05/wds_meta.tsv', './swd_aligned_db_fmt_Lambda_Max_2023-08-08_15-10-55/sws_meta.tsv', './mwd_aligned_db_fmt_Lambda_Max_2023-08-08_15-13-55/mws_meta.tsv', './rod_aligned_db_fmt_Lambda_Max_2023-08-08_15-15-29/rod_meta.tsv', './wds_ni_aligned_db_fmt_Lambda_Max_2023-08-08_15-18-19/wds_ni_meta.tsv', './inv_only_aligned_db_fmt_Lambda_Max_2023-08-08_15-23-06/inv_meta.tsv', './nmoc_aligned_db_fmt_Lambda_Max_2023-08-08_15-24-51/nmoc_meta.tsv']\n",
    "\n",
    "#ref_mod_list = ['./wds_aligned_db_fmt_Lambda_Max_2023-08-08_15-08-05/lgbm.pkl', './swd_aligned_db_fmt_Lambda_Max_2023-08-08_15-10-55/rf.pkl', './mwd_aligned_db_fmt_Lambda_Max_2023-08-08_15-13-55/Lasso.pkl', './rod_aligned_db_fmt_Lambda_Max_2023-08-08_15-15-29/BayesianRidge.pkl', './wds_ni_aligned_db_fmt_Lambda_Max_2023-08-08_15-18-19/gbc.pkl', './inv_only_aligned_db_fmt_Lambda_Max_2023-08-08_15-23-06/LassoLars.pkl', './nmoc_aligned_db_fmt_Lambda_Max_2023-08-08_15-24-51/BayesianRidge.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116664f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "i = 0\n",
    "mafft_exe = 'C:/Users/safra/mafft-win/mafft.bat'\n",
    "seq_add = 'mutant_seqs.fasta'\n",
    "\n",
    "for ref_ali in ref_ali_list:\n",
    "    try:\n",
    "        mut_ali = f'{ref_ali[2:].split(\".\")[0]}_mutant_aligned.fasta'\n",
    "        #print(mut_ali)\n",
    "        cmd = [mafft_exe, '--add', seq_add, '--keeplength', ref_ali , '>', mut_ali ]\n",
    "        aligner = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        out_put = aligner.communicate()[0].decode('utf8')\n",
    "        \n",
    "        #print(out_put)\n",
    "        ref_copy = read_data( f'./{mut_ali}', seq_type = seq_type, is_main=True, gap_threshold=gap_threshold)\n",
    "        mut_test = ref_copy\n",
    "        meta_data = read_data(ref_meta_list[i], seq_type = None, is_main=False)\n",
    "\n",
    "        ref_copy = ref_copy.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "        last_seq = ref_copy.shape[0]\n",
    "        #print(ref_copy.shape)\n",
    "        #print(last_seq)\n",
    "        mut_test = mut_test.iloc[last_seq:].copy()\n",
    "        #print(mut_test)\n",
    "\n",
    "        load_mod = load_obj(ref_mod_list[i])\n",
    "        #print(load_mod)\n",
    "        predictions = load_mod.predict(mut_test)\n",
    "\n",
    "        mut = pd.DataFrame(index=mut_test.index)\n",
    "        mut['Prediction'] = predictions\n",
    "        mut.to_csv(path_or_buf= f'{report_dir}/new_mutant_predictions.csv',mode=\"w\")\n",
    "    except:\n",
    "        pass\n",
    "    i+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBreaks_altenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "1566c31c90cd32f196ccfa15812cd8e8608767ea4549b0419bac2fea141e189a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
