{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f4de42",
   "metadata": {},
   "source": [
    "# <font color=green>deepBreaks Applications</font>\n",
    "## Modeling spectral tuning sites of opsin proteins based on amino-acid sequence...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eed2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils import get_models, get_scores, get_empty_params, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from deepBreaks.models import model_compare_cv, finalize_top, importance_from_pipe, mean_importance, summarize_results\n",
    "from deepBreaks.visualization import plot_scatter, dp_plot, plot_imp_model, plot_imp_all\n",
    "from deepBreaks.preprocessing import write_fasta\n",
    "from sklearn.utils import resample\n",
    "from random import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "#assign your path to folder containing all the datasplits\n",
    "path = './vpod_1.2_data_splits_2024-08-20_16-14-09'\n",
    "meta_data_list = ['wds_meta.tsv','wt_meta.tsv','wt_vert_meta.tsv', 'inv_meta.tsv', 'vert_meta.tsv']\n",
    "seq_data_list = ['wds_aligned_VPOD_1.2_het.fasta','wt_aligned_VPOD_1.2_het.fasta','wt_vert_aligned_VPOD_1.2_het.fasta', 'inv_only_aligned_VPOD_1.2_het.fasta', 'vert_aligned_VPOD_1.2_het.fasta']\n",
    "ds_list = ['wds', 'wt', 'wt_vert', 'inv', 'vert']\n",
    "\n",
    "# name of the phenotype\n",
    "mt = 'Lambda_Max'\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'reg' \n",
    "\n",
    "gap_threshold = 0.5\n",
    "\n",
    "#Specify which properties you want to keep for the amino-acid property encoding:\n",
    "#We keep FIVE by deafult - 'H1, H3, P1, NCI, MASS' \n",
    "#But NINE total are avaliable -'H1, H2, H3, P1, P2, V, NCI, MASS, and SASA' \n",
    "#If you want to keep ALL aa props, just set props_to_keep = 'all'\n",
    "# Or specify the properties in list format props_to_keep = ['H1', 'H3', 'P1', 'NCI', 'MASS']\n",
    "props_to_keep = ['H1', 'H3', 'NCI']\n",
    "props_used = ''\n",
    "for props in props_to_keep:\n",
    "    props_used += props + '_'\n",
    "    \n",
    "n_iterations = 100\n",
    "rng = np.random.default_rng()  # Initialize NumPy's random number generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb69d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta, seq, ds in zip(meta_data_list, seq_data_list, ds_list):\n",
    "    # path to sequences of interest\n",
    "    seqFileName = f'{path}/{seq}' \n",
    "    # path to corresponding metadata of interest\n",
    "    metaDataFileName = f'{path}/{meta}' \n",
    "    # making a unique directory for saving the reports of the analysis\n",
    "    #print('direcory preparation')\n",
    "    dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    report_dir = str(f'{ds}_{props_used}_bootstrap_100_{dt_label}')\n",
    "    os.makedirs(report_dir)\n",
    "\n",
    "    #print('reading meta-data')\n",
    "    # importing metadata\n",
    "    meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "    metaFile = metaDataFileName.split('/')[1]\n",
    "    # importing sequences data\n",
    "    #print('reading fasta file')\n",
    "    tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=gap_threshold)\n",
    "    #merging in lambda max values, simultaneously dropping all sequences without entries in metadata file\n",
    "    tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "    #tr.shape\n",
    "    seqFile = seqFileName.split('/')[2]\n",
    "    #print(seqFile)\n",
    "    seqFile = seqFile.split('.')[0]+'.'+seqFile.split('.')[1]\n",
    "    write_fasta(dat = tr, fasta_file = f'{seqFile}_gap_dropped.fasta' , report_dir = report_dir)\n",
    "\n",
    "    y = tr.loc[:, mt].values\n",
    "    tr.drop(mt, axis=1, inplace=True)\n",
    "\n",
    "    full_tr = tr.copy()\n",
    "\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        #settingthe paramaters for our ML pipeline\n",
    "        prep_pipeline = make_pipeline(\n",
    "            steps=[\n",
    "                ('mc', MisCare(missing_threshold=0.05)),\n",
    "                ('cc', ConstantCare()),\n",
    "                ('aa_prop', AminoAcidPropertyEncoder(props_to_keep = props_to_keep)),\n",
    "                ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=False)),\n",
    "                ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=False))\n",
    "            ])\n",
    "        tr = full_tr\n",
    "        random_state = rng.integers(0, 2**32 - 1)  # Generate a new random seed for perturbation\n",
    "        X_res, y_res = resample(tr, y, random_state=random_state)\n",
    "        \n",
    "        #training models\n",
    "        report, top = model_compare_cv(X=X_res, y=y_res, preprocess_pipe=prep_pipeline,\n",
    "                                    models_dict=get_models(ana_type=ana_type, dataset = ds),\n",
    "                                    scoring=get_scores(ana_type=ana_type),\n",
    "                                    report_dir=report_dir,\n",
    "                                    cv=10, ana_type=ana_type, cache_dir=report_dir)\n",
    "\n",
    "                                    \n",
    "        #setting parameters for tuning the top performing models\n",
    "        prep_pipeline = make_pipeline(\n",
    "            steps=[\n",
    "                ('mc', MisCare(missing_threshold=0.05)),\n",
    "                ('cc', ConstantCare()),\n",
    "                ('aa_prop', AminoAcidPropertyEncoder(props_to_keep = props_to_keep)),\n",
    "                ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=True)),\n",
    "                ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=True))\n",
    "            ])\n",
    "\n",
    "        modified_top = []\n",
    "        mtml = []\n",
    "        for model in top:\n",
    "            modified_top.append(make_pipeline(steps=[('prep', prep_pipeline), model.steps[-1]]))\n",
    "            my_top_models = str(model[1:])\n",
    "            #print(my_top_models)\n",
    "            my_top_models = my_top_models.split(\"'\")[3]\n",
    "            mtml.append(my_top_models)\n",
    "\n",
    "        #tuning the top 3 performing models \n",
    "        top = finalize_top(X=X_res, y=y_res, top_models=modified_top, grid_param=get_empty_params(),report_dir=report_dir, cv=10)\n",
    "        #summarize the results by extracting feature importance and p-values and grouping correlated features.\n",
    "        sr = summarize_results(top_models=top, report_dir=report_dir)\n",
    "        mean_imp = mean_importance(top, report_dir=report_dir)\n",
    "        \n",
    "        try:\n",
    "            original_file = f'{report_dir}/importance_report.csv'  \n",
    "            new_file = f'{report_dir}/importance_report_iter_{str(i)}.csv' \n",
    "            shutil.copy(original_file, new_file)\n",
    "            os.remove(original_file)\n",
    "        except:\n",
    "            raise Exception('Cannot copy or delete importance_report file either because it does not exist or the direcotry is incorrect')\n",
    "        \n",
    "        try:\n",
    "            original_file = f'{report_dir}/model_report.csv'  \n",
    "            new_file = f'{report_dir}/model_report_iter_{str(i)}.csv' \n",
    "            shutil.copy(original_file, new_file)\n",
    "            os.remove(original_file)\n",
    "        except:\n",
    "            raise Exception('Cannot copy or delete model_report file either because it does not exist or the direcotry is incorrect')\n",
    "\n",
    "        try:\n",
    "            for model in mtml:\n",
    "                original_file = f'{report_dir}/{model}.pkl'  \n",
    "                new_file = f'{report_dir}/{model}_{str(i)}.pkl' \n",
    "                shutil.copy(original_file, new_file)\n",
    "                os.remove(original_file)\n",
    "        except:\n",
    "            raise Exception('Cannot copy or delete model pkl file either because it does not exist or the direcotry is incorrect')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBreaks_altenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "1566c31c90cd32f196ccfa15812cd8e8608767ea4549b0419bac2fea141e189a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
