{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>deepBreaks Application</font>\n",
    "Modeling the phenotypes and spectral tuning sites of opsin proteins based on amino-acid sequence... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>Application Focus:</font> \n",
    "<font color=white>Phylogenetically Weighted Cross Validation Iteratative Testing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What factors are we interested in observing the effects of on model performance?**\n",
    "* percentile threshold (aka - our desired minimum distance threshold)\n",
    "* relation_mode handeling methods (leave_out, max_mean, merge, random)\n",
    "* n_folds - How sensitive is this approach to differnt numbers of cross-validation folds? \n",
    "* tree models - How sensitive is this approach to different algorythms\n",
    "\n",
    "**What is the best way to loop through these conditions?**\n",
    "1. For each tree in a folder of trees (each constructed using a different algorythm)\n",
    "2. For each relation handeling method \n",
    "3. For each n_folds in a range of fold numbers to test\n",
    "4. For each percentile threshold in a range of desired thresholds to test\n",
    "5. For each model algorythm in the deepBreaks pipeline\n",
    "[Each subsequent number is nested in the previous - so for one tree we do all forms of relation handeling - and for all forms of relation handeling we go through all of a selected range of cv fold sizes and then we go through all percentile thresholds  in a list of percentile thresholds]\n",
    "\n",
    "**What are the set paramaters or range of parameters we'll test as differnt conditions?**\n",
    "* Tree Models / Tree Used - [for WT opsins] LG+F+R7 (top model), Q.pfam+F+R7, WAG+F+R7 // [for WT vert opsins] LG+F+R6, Q.pfam+F+R6, WAG+F+R6\n",
    "* Relation Handeling Methods - leave_out, max_mean, merge, random\n",
    "* Number of Folds - [5,8,10,12,15,20]\n",
    "* Percentile Threshold Range - 1st -> 95th Percentiles - divied up into 40 percentile points in a list\n",
    "* Normal selection of models from first round of training (pre-grid-search)\n",
    "\n",
    "**General Workflow**\n",
    "* Read a folders contents [should only contain phylogentic trees to test] and select a phylogentic tree file\n",
    "* Load target phylogentic tree (_should be based on corresponding fasta file of sequence data_)\n",
    "* Create new folder speific to testing that phylogentic tree - can use the name as the basis for naming the new folder - include the data and time using 'datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')'\n",
    "* Create either a new excel compatible csv file for recording the results of each test iteration or seperate excel files by number of folds, recording all upstream information about the test conditions in the file name and/or in some section of the excel/csv file. from each round of testing we should group results by Tree used (can be tree file name), then by relation handeling method, then by number of folds and then by model, and the corresponding R^2 value for a given threshold. (My end goal is to be able to graph all these different conditions).\n",
    "NOTE - Following each round of model training the results are recorded in a csv file named 'model_report.csv' - we'll need to extract the R^2 values for each model from that column. On the first run we'll aslo need to extract all the model names so we can add them to the results file where we're recording model performance vs. threshold. \n",
    "\n",
    "**IGNORE THIS FOR NOW**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading neccessary vpod scripts for phylogenetic cross validation\n",
    "from vpod_scripts.phylo_weighted_cv import get_dist_matrix_from_tree, percentile_threshold, phylo_weighted_cv\n",
    "\n",
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils import get_models, get_scores, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from deepBreaks.models import model_compare_cv\n",
    "from deepBreaks.preprocessing import write_fasta\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import shutil \n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "#assign your path to folder containing all the datasplits\n",
    "path = './vpod_1.2_data_splits_2024-08-20_16-14-09'\n",
    "# path to sequences of interest\n",
    "seqFileName = f'{path}/wt_aligned_VPOD_1.2_het.fasta' \n",
    "# path to corresponding metadata of interest\n",
    "metaDataFileName = f'{path}/wt_meta.tsv' \n",
    "\n",
    "# name of the phenotype\n",
    "mt = 'Lambda_Max'\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'reg' \n",
    "\n",
    "gap_threshold = 0.50\n",
    "\n",
    "#Whether or not you want to drop the reference sequence from the training data- Usually 'Bovine' or 'Squid'\n",
    "drop_ref = False\n",
    "\n",
    "# making a unique directory for saving the reports of the analysis\n",
    "print('direcory preparation')\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seqFile = seqFileName.split('/')[2]\n",
    "#print(seqFile)\n",
    "seqFile = seqFile.split('.')[0]+ '.'+ seqFile.split('.')[1]\n",
    "#print(seqFile)\n",
    "report_dir = str(seqFile +'_' + mt + '_' + dt_label)\n",
    "os.makedirs(report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('reading meta-data')\n",
    "# importing metadata\n",
    "meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "# importing sequences data\n",
    "print('reading fasta file')\n",
    "\n",
    "tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=gap_threshold)\n",
    "\n",
    "shutil.copy2(f'{seqFileName}',report_dir)\n",
    "write_fasta(dat = tr, fasta_file = f'{seqFile}_gap_dropped.fasta' , report_dir = report_dir)\n",
    "\n",
    "tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and Conditions to Test\n",
    "relation_handling_methods = [\"leave_out\", \"max_mean\", \"merge\", \"random\"]\n",
    "\n",
    "n_folds_range = [5, 8, 10, 12, 15, 20]\n",
    "percentile_threshold_range = list(range(1, 96, int(95 / 40))) # Generate 40 percentile points\n",
    "tree_folder = \"c:/Users/safra/Documents/GitHub/visual-physiology-opsin-db/scripts_n_notebooks/vpod_ML_workflows/subtests/work_in_progress/phylo_weighted_cv/opsin_wt_tree/vpod_1.2_wt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.025)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.1, keep=False)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.01, keep=False))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree_file in os.listdir(tree_folder):\n",
    "    if tree_file.endswith(\".treefile\"): # Process only tree files\n",
    "        # Load phylogenetic tree and obtain pair-wise distance matrix\n",
    "        tree_path = os.path.join(tree_folder, tree_file)\n",
    "        dist_matrix, tip_names = get_dist_matrix_from_tree(tree_path)\n",
    "        \n",
    "        # Create new folder for results\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        results_folder = f\"{tree_file.split('.')[0]}.{tree_file.split('.')[1]}_phylo_cv_{timestamp}\"\n",
    "        os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "        # Create results file (choose CSV or Excel based on your preference)\n",
    "        results_file = os.path.join(results_folder, f\"{tree_file.split('.')[0]}.{tree_file.split('.')[1]}_phylo_cv_results.csv\")\n",
    "        with open(results_file, \"w\") as f:\n",
    "            f.write(\"Tree,Relation_Handling,N_Folds,Model,Threshold,R2,MAE,MAPE,MSE,RMSE\\n\") # Header\n",
    "\n",
    "        for relation_method in relation_handling_methods:\n",
    "            for n_folds in n_folds_range:\n",
    "                for percentile in percentile_threshold_range:\n",
    "                    percentile_dist_threshold = percentile_threshold(dist_matrix, percentile=percentile)\n",
    "                    tip_to_fold = phylo_weighted_cv(distance_matrix=dist_matrix, tip_names=tip_names, n_folds=n_folds, distance_threshold=percentile_dist_threshold, relation_mode=relation_method)\n",
    "                    tr_temp = tr.copy()\n",
    "                    tr_temp = tr_temp.reindex(tip_to_fold.index)\n",
    "                    tr_temp['Fold'] = tip_to_fold['Fold']\n",
    "                    if relation_method == 'leave_out':\n",
    "                        tr_temp = tr_temp[tr_temp['Fold'] != -1]\n",
    "                    tr_phylo_folds = tr_temp['Fold'].tolist()\n",
    "                    tr_temp.drop('Fold', axis=1, inplace=True)\n",
    "                    y = tr_temp.loc[:, mt].values\n",
    "                    tr_temp.drop(mt, axis=1, inplace=True)\n",
    "                    \n",
    "                    if tr_temp.shape[0] > 100:\n",
    "                        # Run deepBreaks pipeline (assuming necessary functions exist)\n",
    "                        report, top = model_compare_cv(X=tr_temp, y=y, preprocess_pipe=prep_pipeline,\n",
    "                                models_dict=get_models(ana_type=ana_type),\n",
    "                                scoring=get_scores(ana_type=ana_type),\n",
    "                                report_dir=report_dir,\n",
    "                                cv=tr_phylo_folds, ana_type=ana_type, cache_dir=report_dir)\n",
    "                        # Record R^2 values for each model\n",
    "                        with open(results_file, \"a\") as f:\n",
    "                            for model_name, r2_value, mae_value, mape_value, mse_value, rmse_value in zip(report.index.to_list(), report[\"R2\"],report[\"MAE\"],report[\"MAPE\"],report[\"MSE\"],report[\"RMSE\"]):\n",
    "                                f.write(f\"{tree_file},{relation_method},{n_folds},{model_name},{percentile},{r2_value},{mae_value},{mape_value},{mse_value},{rmse_value}\\n\")\n",
    "                        #removing the default model report file between iterations\n",
    "                        os.remove(f'{report_dir}/model_report.csv')\n",
    "                        shutil.rmtree(f'{report_dir}/joblib')\n",
    "                    else:\n",
    "                        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBreaks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
